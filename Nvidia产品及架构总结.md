# **产品系列**

## **消费级GPU系列**

- GeForce系列：

- GeForce Now：

## **专业级GPU系列**

- Quadro系列：

- Titan系列：

## **数据中心和云计算系列**

- NVIDIA A100：

- NVIDIA H100：

## **自动驾驶和机器人系列**

- NVIDIA DRIVE：

- NVIDIA Jetson：

## **其他产品**

- NVIDIA Shield：

- NVIDIA Studio：

# **架构**

## **1.** **NV1** **和** **NV2**

- 发布时间：1995年左右
- 特点：英伟达的早期架构，主要用于游戏和图形加速。

## **2.** **RIVA 128** **和** **RIVA TNT**

- 发布时间：1997年和1998年
- 特点：引入了硬件加速的3D图形功能，为后续的架构奠定了基础。

## **3.** **GeForce 256**

- 发布时间：1999年
- 代表产品：GeForce 256
- 特点：被认为是第一款真正的GPU（Graphics Processing Unit），引入了硬件T&L（Transform and Lighting）功能。

## **4.** **GeForce 3**

- 发布时间：2001年
- 代表产品：GeForce3 Ti 200, GeForce3 Ti 500
- 特点：引入了可编程着色器（Shader），为后来的可编程图形管线奠定了基础。

## **5.** GeForce 6（代号：NV40）

- 发布时间：2004年
- 代表产品：GeForce 6800 Ultra, GeForce 6600 GT
- 特点：引入了统一着色器架构，支持DirectX 9.0c和Shader Model 3.0。

## **6.** GeForce 8（代号：G80）

- 发布时间：2006年
- 代表产品：GeForce 8800 GTX, GeForce 8800 GTS
- 特点：引入了统一着色器架构，支持DirectX 10和Shader Model 4.0，标志着GPU开始向通用计算领域扩展。

## **7.** Fermi

- 发布时间：2010年
- 代表产品：GeForce GTX 480, GeForce GTX 580
- 特点：专为高性能计算设计，引入了ECC内存支持，提高了计算精度和可靠性。

## **8.** Kepler

- 发布时间：2012年
- 代表产品：GeForce GTX 680, GeForce GTX 780
- 特点：提高了能效比，引入了动态超级分辨率（DSR）和GPU Boost技术，增强了游戏性能。

## **9.** Maxwell

- 发布时间：2014年
- 代表产品：GeForce GTX 750 Ti, GeForce GTX 980
- 特点：进一步提高了能效比，引入了新的电源管理技术，如Battery Boost和Optimus。

## **10.** Pascal

- 发布时间：2016年
- 代表产品：GeForce GTX 1080, GeForce GTX 1070, GeForce GTX 1060
- 特点：引入了HBM2内存和NVLink互连技术，提高了计算和数据传输性能，广泛应用于游戏、专业图形和数据中心。

## **11.** Volta

- 发布时间：2017年
- 代表产品：Tesla V100, Titan V
- 特点：专为深度学习和人工智能设计，引入了Tensor Core，提供了强大的AI计算能力。

## **12.** **Turing**

- 发布时间：2018年
- 代表产品：GeForce RTX 2080 Ti, GeForce RTX 2080, GeForce RTX 2070
- 特点：引入了实时光线追踪（Ray Tracing）和AI加速的Tensor Core，广泛应用于GeForce RTX系列显卡。

## **13.** **Ampere**

英伟达（NVIDIA）推出的第八代GPU架构，以著名科学家安培（André-Marie Ampère）的名字命名。Ampere架构在2020年发布，是英伟达在数据中心、高性能计算（HPC）、人工智能（AI）和游戏领域的重要创新。

- 发布时间：2020年

- 代表产品：GeForce RTX 3090, GeForce RTX 3080, GeForce RTX 3070

- - A100是基于Ampere架构的数据中心GPU，专为AI、HPC和云计算设计。它集成了数千个第二代Tensor Core，支持HBM2内存，并提供了高达2 TB/s的内存带宽。A100还支持MIG技术，提供了灵活的资源分配能力。
  - GeForce RTX 30系列是基于Ampere架构的消费级GPU，包括RTX 3090、RTX 3080和RTX 3070等型号。这些GPU集成了第二代Tensor Core和RT Core，提供了强大的游戏性能和实时光线追踪能力。

- 特点：进一步增强了Tensor Core的性能，提供了更高的AI计算能力和实时光线追踪性能，应用于A100数据中心GPU和GeForce RTX 30系列显卡。

## **14.** **Hopper**

以计算机科学家Grace Hopper的名字命名。Hopper架构在性能、能效和AI计算能力方面都有显著的提升，主要应用于数据中心、高性能计算（HPC）和人工智能（AI）领域。

- 发布时间：2022年

- 代表产品：H100、DGX H100

- - H100是基于Hopper架构的数据中心GPU，专为AI、HPC和云计算设计。它集成了数千个第三代Tensor Core，支持HBM3内存，并提供了高达900 GB/s的内存带宽。H100还支持NVLink 4.0，提供了更高的GPU间通信带宽。
  - DGX H100是基于H100 GPU的超级计算机系统，专为深度学习和科学计算设计。它集成了多个H100 GPU，通过NVLink互连技术实现高效的数据交换，提供了强大的计算能力和高吞吐量。

- 特点：是Ampere架构的继任者，提供了更高的性能和效率，应用于H100数据中心GPU和其他高性能计算产品。

Hopper架构和其代表性产品H100广泛应用于以下领域：

# **NVLink**

NVLink是英伟达（NVIDIA）开发的一种高速互连技术，旨在提供GPU之间以及GPU与CPU之间的高带宽、低延迟通信。NVLink技术最初在2016年推出，随着每一代新架构的发布，NVLink的性能和功能也在不断增强。

## **发展历程**

- 第一代NVLink：在Pascal架构中引入，提供单向20 GB/s的带宽。
- 第二代NVLink：在Volta架构中引入，提供单向300 GB/s的带宽。
- 第三代NVLink：在Ampere架构中引入，提供单向600 GB/s的带宽。

## **关键特点**

- 高带宽：NVLink提供了比传统PCIe接口更高的带宽。例如，第一代NVLink（在Pascal架构中引入）提供了单向20 GB/s的带宽，而第三代NVLink（在Ampere架构中引入）提供了单向600 GB/s的带宽。这种高带宽对于需要大量数据交换的并行计算任务至关重要。
- **低延迟**：NVLink不仅提供高带宽，还具有低延迟的特点。低延迟有助于提高GPU之间的通信效率，特别是在进行复杂的数据并行计算时。
- **多GPU支持**：NVLink支持多个GPU之间的直接连接，使得构建多GPU系统更加简单和高效。通过NVLink，多个GPU可以形成一个紧密耦合的计算集群，共同完成大规模的计算任务。
- **CPU互连**：除了GPU之间的互连，NVLink还可以用于GPU与CPU之间的直接连接。这种直接连接可以绕过传统的PCIe总线，提供更高的带宽和更低的延迟，适用于需要GPU和CPU紧密协作的应用场景。
- **可扩展性**：NVLink技术具有良好的可扩展性，可以支持不同规模的系统配置。从小型的双GPU系统到大型的高性能计算集群，NVLink都能提供高效的互连解决方案。

## **关键技术原理**

### **点对点互连**

NVLink采用点对点（point-to-point）互连方式，这意味着每个NVLink链路直接连接两个设备（例如两个GPU或一个GPU和一个CPU）。这种直接连接方式避免了传统总线架构中的共享带宽问题，从而提供了更高的带宽和更低的延迟。

### **高带宽传输**

NVLink使用多通道并行传输技术，通过多条物理链路同时传输数据。每个NVLink链路包含多个通道，每个通道可以独立传输数据。例如，第一代NVLink包含18个通道，每个通道的传输速率为25 Gbps，总带宽达到单向20 GB/s。随着每一代新架构的发布，通道数量和传输速率都有所增加，从而提供了更高的总带宽。

### **低延迟通信**

NVLink通过优化数据传输协议和物理链路设计，实现了低延迟通信。低延迟对于需要快速响应的应用场景（如实时渲染和实时数据处理）至关重要。NVLink的低延迟特性得益于其直接的点对点连接和高效的数据传输协议。

### **灵活的拓扑结构**

NVLink支持灵活的拓扑结构，可以构建不同规模和配置的互连系统。例如，多个GPU可以通过NVLink形成一个紧密耦合的计算集群，共同完成大规模的计算任务。此外，NVLink还可以用于GPU与CPU之间的直接连接，提供更高的带宽和更低的延迟。

### **兼容性和扩展性**

NVLink技术具有良好的兼容性和扩展性。随着每一代新架构的发布，NVLink的性能和功能都在不断增强，但同时也保持了向后兼容性，使得旧的硬件和软件可以与新的硬件和软件协同工作。此外，NVLink技术还支持不同规模的系统配置，从小型的双GPU系统到大型的高性能计算集群，NVLink都能提供高效的互连解决方案。

### **物理层和协议层**

NVLink的实现涉及物理层和协议层两个方面。物理层负责实际的数据传输，包括信号的调制、解调、传输和接收。协议层负责数据传输的管理和控制，包括数据包的封装、路由、错误检测和纠正等。通过优化物理层和协议层的设计，NVLink实现了高效、可靠的数据传输。

### **总结**

NVLink的技术原理基于点对点互连、高带宽传输、低延迟通信、灵活的拓扑结构、兼容性和扩展性以及优化的物理层和协议层设计。这些技术原理共同构成了NVLink高速互连技术的核心，为GPU之间以及GPU与CPU之间的通信提供了强大的支持。

# **HBM**

HBM（High Bandwidth Memory）是一种高带宽内存技术，由AMD和SK Hynix等公司共同开发，旨在为高性能计算和图形处理提供更高的内存带宽。HBM技术通过将多个DRAM芯片堆叠在一起，并通过硅通孔（TSV）技术进行垂直互连，从而实现高带宽和低功耗。

## **HBM1**

- 发布时间：2015年

- 特点：

- - 第一代HBM技术，引入了堆叠DRAM和TSV技术。
  - 每个堆栈包含4个或8个DRAM芯片，每个芯片的容量为4 GB。
  - 提供128 GB/s的带宽，每个堆栈有4个通道，每个通道的传输速率为1 Gbps。

- 优点：

- - 高带宽：相比传统GDDR5内存，HBM1提供了更高的带宽。
  - 低功耗：通过堆叠和TSV技术，HBM1实现了较低的功耗。

- 缺点：

- - 容量有限：每个堆栈的容量相对较低，限制了其在某些应用中的使用。
  - 成本较高：由于新技术和制造工艺，HBM1的成本相对较高。

## **HBM2**

- 发布时间：2016年

- 特点：

- - 第二代HBM技术，进一步提升了带宽和容量。
  - 每个堆栈包含8个DRAM芯片，每个芯片的容量为8 GB。
  - 提供256 GB/s的带宽，每个堆栈有8个通道，每个通道的传输速率为2 Gbps。

- 优点：

- - 更高的带宽和容量：HBM2相比HBM1提供了更高的带宽和容量，适用于更广泛的高性能应用。
  - 改进的能效：HBM2在提供更高性能的同时，也改进了能效。

- 缺点：

- - 成本仍然较高：尽管技术有所改进，但HBM2的成本仍然相对较高。

## **HBM2E**

- 发布时间：2019年

- 特点：

- - HBM2的增强版，提供了更高的传输速率。
  - 每个堆栈包含8个DRAM芯片，每个芯片的容量为8 GB。
  - 提供400 GB/s的带宽，每个堆栈有8个通道，每个通道的传输速率为3.6 Gbps。

- 优点：

- - 更高的传输速率：HBM2E在HBM2的基础上进一步提升了传输速率，提供了更高的带宽。
  - 兼容性：HBM2E与HBM2兼容，使得现有系统可以无缝升级。

- 缺点：

- - 成本：HBM2E的成本仍然相对较高，限制了其在某些市场的普及。

## **HBM3**

- 发布时间：2021年

- 特点：

- - 第三代HBM技术，提供了更高的带宽和容量。
  - 每个堆栈包含8个DRAM芯片，每个芯片的容量为16 GB。
  - 提供1 TB/s的带宽，每个堆栈有8个通道，每个通道的传输速率为5.6 Gbps到6.4 Gbps。

- 优点：

- - 更高的带宽和容量：HBM3提供了前所未有的带宽和容量，适用于最苛刻的高性能计算和AI应用。
  - 改进的能效：HBM3在提供更高性能的同时，也进一步改进了能效。

- 缺点：

- - 成本：HBM3的成本仍然相对较高，但随着技术的成熟和规模化生产，成本有望逐渐降低。

# **Tensor Core**

Tensor Core是英伟达（NVIDIA）在其GPU架构中引入的一种专用硬件单元，旨在加速深度学习和人工智能（AI）任务中的矩阵运算。Tensor Core最初在Volta架构中引入，随后在后续的架构（如Turing和Ampere）中得到了进一步的增强和优化。

## **发展历程**

- Volta架构：

- - 在Volta架构中，Tensor Core首次亮相，提供了4x4x4的FP16矩阵乘法和累加运算能力。

- Turing架构：

- - 在Turing架构中，Tensor Core得到了进一步的增强，支持更多的数据类型和运算模式。

- Ampere架构：

- - 在Ampere架构中，Tensor Core引入了对稀疏矩阵运算的支持，提供了更高的性能和能效。

## **关键特点**

1. 专用矩阵运算单元：

1. 高吞吐量：

1. 支持多种数据类型：

1. 稀疏矩阵运算：

1. 软件支持：

## **如何加速矩阵运算**

### **1.** **专用硬件设计**

Tensor Core是专门设计用于执行矩阵乘法和累加运算（fused multiply-add, FMA）的硬件单元。与传统的CUDA核心相比，Tensor Core在执行这些特定类型的运算时具有更高的效率和吞吐量。

### **2.** **高吞吐量矩阵运算**

Tensor Core可以在一个时钟周期内执行多个矩阵运算。例如，在Volta架构中，每个Tensor Core可以在一个时钟周期内执行4x4x4的FP16矩阵乘法和累加运算。这种高吞吐量的矩阵运算能力显著加速了深度学习模型中的卷积、全连接层和循环层等操作。

### **3.** **混合精度计算**

Tensor Core支持混合精度计算，即在不同的精度级别（如FP16和FP32）之间进行矩阵运算。这种混合精度计算可以在保持模型精度的同时，提高计算速度和能效。例如，Tensor Core可以执行FP16的矩阵乘法，并将结果累加到FP32的累加器中，从而在保持高精度的同时提高运算速度。

### **4.** **稀疏矩阵运算**

在Ampere架构中，Tensor Core引入了对稀疏矩阵运算的支持。稀疏矩阵是指大部分元素为零的矩阵，这种矩阵在深度学习模型中很常见。通过利用稀疏矩阵的特性，Tensor Core可以跳过零元素的计算，从而进一步提高矩阵运算的速度和能效。

### **5.** **软件优化和库支持**

Tensor Core得到了英伟达深度学习软件栈的全面支持，包括CUDA、cuDNN和TensorRT等。这些软件库提供了高效的API和优化算法，使得开发者可以轻松利用Tensor Core的强大计算能力。例如，cuDNN库提供了针对Tensor Core优化的卷积和全连接层算法，TensorRT库提供了针对Tensor Core优化的模型推理引擎。

### **6.** **并行计算和数据流优化**

Tensor Core的设计还考虑了并行计算和数据流优化。通过在多个Tensor Core之间并行执行矩阵运算，并优化数据流和内存访问模式，Tensor Core可以进一步提高矩阵运算的效率和吞吐量。