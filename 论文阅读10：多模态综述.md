# 多模态预训练任务

## 掩码语言建模预训练任务

掩码语言建模(Masked Language Modeling,MLM)预训练任务是指在句子表示中随机掩盖一些字词，然后模型基于其他的文本标记和所有的图像标记预测这些被掩盖的标记的一种任务。  

![image-20230928100030531](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20230928100030531.png)

损失函数如下：
$$
L_{MLM}(\theta)=-E_{(w,v) \sim D}log {P_\theta}{(w_m | w_{\backslash m},v)}
$$
其中$V$代表从图像提取的特征向量，$w$表示输入文本对应的特征向量(即词嵌入).$D$代表用于训练模型的数据集，$D$是一组图像文本对，每个对由一幅图像和一个相应的文本描述组成，m表示输入文本的第$m$个词。${P_\theta}{(w_m | w_{\backslash m},v)}$表示在参数化$\theta$下，在文本$w_{\backslash m},v$和相应图像$v$中，第$m$个单词的条件概率。



## 掩码区域建模预训练任务

### 掩码区域分类预训练任务

类似于 MLM，掩码区域建模（Masked Region Modeling，MRM）同样可以采样图像区域，并以 15% 的概率掩盖它们的视觉特征。在给定剩余区域和所有单词的情况下，训练该模型重建掩码区域。  

![image-20230928101832321](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20230928101832321.png)

MRM 的最小化负似然函数为  ：
$$
L_{MRM}(\theta)=E_{(w,v) -sim D}log f_{\theta}(v_m | v_{\backslash m},w)
$$
其中$log f_{\theta}(v_m | v_{\backslash m},w)$表示在MRM任务参数化下，给定图像中的几个区域$v_ {\backslash m}$和相应的输入文本$w$特征的条件概率密度函数

掩码区域分类（Masked Region Classification，MRC）预训练任务，需要在区域标记中随机掩盖一些字词，然后根据其他的图片标记和所有的文本词语预测这些被掩盖的字词对应的区域的真实标签。

损失函数为：
$$
f_\theta (v_m | v _{\backslash m},w)=\sum _{i=1} ^M CE(c(v_m ^{(i)}),g_ \theta (v_m ^{(i)}))
$$
其中$CE$表示交叉熵损失，$M$是采样区域数，$g_ \theta$是一个神经网络，将输入的文本和区域映射到预测的区域级特征的表示；c是一个函数，返回区域级特征的真实标签。  

### 掩码区域分类KL散度预训练任务　  

掩码区域分类 KL 散度（Masked Region Classification withKullback-Leibler divergence，MRC-KL）预训练任务也是随机掩盖区域标记，区别在于它不是做分类任务，而是需要计算分布差异  

MRC 任务是预测一个被掩盖的视觉区域的对象类别，激活未掩盖的视觉上下文和标记。MRC-KL变量测量预测分布的 KL散度，而不是针对单个对象类的交叉熵  。

最小化两个分布之间的 KL差距  ：
$$
f_\theta (v_m | v _{\backslash m},w)=\sum _{i=1} ^M D_{KL}(\tilde c(v_m ^{(i)}),g_ \theta (v_m ^{(i)}))
$$
其中$\tilde c$表示图像视觉特征上的分布，$\tilde c(v_m ^{(i)})$表示概率函数，指示图像的哪些部分与给定的文本输入相关。  



### 掩码区域特征回归预训练任务

MRC 可以被视为视觉 MLM，需要 V&L 模型预测掩盖对象 的 类 别 。 掩 码 区 域 特 征 回 归（Masked Region Feature
Regression，MRFR）进一步要求 V&L 模型恢复掩盖对象区域的视觉特征。MRFR 预测被掩盖掉的感兴趣区域（Regionof Interest，RoI）特征。随机掩盖 15% 的 RoI（全部替换为零向量），损失为输出 RoI 特征与特征抽取模型的 RoI 特征间的L2距离 。



## ITM预训练任务

![image-20230928105944350](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20230928105944350.png)

在图像‒文本配对（Image-Text Matching，ITM）任务中，需要将输入的图像‒文本配对随机替换其中的图片或者文本，最后预测输入的图像和文本是否有对应关系，属于一个二分类的问题。  

损失函数如下：
$$
L_{ITM}(\theta)=-E_{(w,v) \sim D}[ylog s_ \theta (w,v)+(1-y)log(1-s_\theta(w,v))]
$$
其中，$y$表示输入文本和图像对$(w,v)$在语义上是否一致的真是二进制标签，$s_\theta(w,v)$是ITM模型参数$\theta$下预测一致性概率。



# 多模态数据融合

根据融合时期、融合程度和融合方式的不同，可将多模态数据融合分为早期融合、晚期融合和混合融合  

数据层和特征层的融合均称为早期融合  。

晚期融合方法也称决策级融合方法，先用对应的模型对各个模态建模训练，再融合多个模型输出的结果。  

混合融合方法在综合了早期融合和晚期融合优点的同时，也增加了训练的难度。  

![image-20230928111956977](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20230928111956977.png)

![image-20230928112950706](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20230928112950706.png)



# 多模态预训练模型

多模态预训练模型一般分为单流结构和双流结构。单流式预训练模型在早期就将不同模态的信息融合，通过注意力机制完成多模态交互。将来自不同模态的特征结合在一起输入模型进行交互  。

双流模型则先使用不同的结构分别对两个模态编码，再通过互注意力（co-attention）机制完成跨模态融合。视觉预训练模型的网络层数较多，所以在多模态交互之前所需的处理也较少，而文本特征则没有经过较深模型的处理。双流模型结构灵活，可以根据具体情况决定在交互前对不同模态的处理方式。  



![image-20230928113156363](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20230928113156363.png)

![image-20230928113729390](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20230928113729390.png)





【1】王惠茹, 李秀红, 李哲, 马春明, 任泽裕, 杨丹. 多模态预训练模型综述[J]. 计算机应用, 2023, 43(4): 991-1004.