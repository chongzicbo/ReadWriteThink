

# 参考：

[1] [自然语言处理中的Attention机制总结_CODE and POEM-CSDN博客_attention](https://blog.csdn.net/hahajinbu/article/details/81940355)

[2] [Attention 面试向知识点背书_MinyounZhang的博客-CSDN博客](https://blog.csdn.net/MinyounZhang/article/details/108370623)

[3] [NLP中的 Attention 机制（不定期更新） - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/59698165)

[4] [(64 封私信 / 80 条消息) 目前主流的attention方法都有哪些？ - 知乎 (zhihu.com)](https://www.zhihu.com/question/68482809)

[5] [机器学习面试之Attention · 语雀 (yuque.com)](https://www.yuque.com/liwenju/kadtqt/ulavrv)

[6] [【面试QA】Attention (bbsmax.com)](https://www.bbsmax.com/A/RnJWyoLvdq/)

[7] [我想去面试系列——Attention与Transformer - 想飞的小菜鸡 (vodkazy.cn)](https://vodkazy.cn/2020/10/29/我想去面试系列——Attention与Transformer/)