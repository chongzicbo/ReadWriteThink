## H264编码过程

以下图为例：

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107190849982-1182529443.png)

### 划分宏块

> 宏块是编码标准的基本处理单元，通常它的大小也为 16x16 像素。16X16 的宏块上可以划分出更小的子块。子块的大小可以是 8X16､ 16X8､ 8X8､ 4X8､ 8X4､ 4X4。

H264 默认是使用 16X16 大小的区域作为一个宏块，也可以划分成 8X8 大小的宏块。

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107190914625-374567205.png)

划分好宏块后，**计算宏块的象素值**。划分宏块后，并不会直接计算每个宏块的像素值。相反，H.264通过预测、变换、量化和熵编码等步骤来处理宏块，最终生成压缩后的数据流。

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107190921396-267156799.png)

以此类推，计算一幅图像中每个宏块的像素值，所有宏块都处理完后如下面的样子。

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107190926907-1799104474.png)

### 划分子块

H264 对比较平坦的图像使用 16X16 大小的宏块。但为了更高的压缩率，还可以在 16X16 的宏块上更划分出更小的子块。

子块的大小可以是 8X16､ 16X8､ 8X8､ 4X8､ 8X4､ 4X4，非常的灵活。

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107190952451-39526249.png)

上幅图中，红框内的 16X16 宏块中大部分是蓝色背景，而三只鹰的部分图像被划在了该宏块内，为了更好的处理三只鹰的部分图像，H264就在 16X16 的宏块内又划分出了多个子块。

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107190959136-1050514686.png)

这样再经过帧内压缩，可以得到更高效的数据。下图是分别使用mpeg-2和H264对上面宏块进行压缩后的结果。其中左半部分为MPEG-2子块划分后压缩的结果，右半部分为H264的子块划压缩后的结果，可以看出H264的划分方法更具优势。

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107191009300-1374183671.png)

宏块划分好后，就可以对H264编码器缓存中的所有图片进行分组了。

### 帧分组

对于视频数据主要有两类数据冗余，一类是时间上的数据冗余，另一类是空间上的数据冗余。.其中时间上的数据冗余是最大的。下面我们就先来说说视频数据时间上的冗余问题。

为什么说时间上的冗余是最大的呢？假设摄像头每秒抓取30帧，这30帧的数据大部分情况下都是相关联的。也有可能不止30帧的的数据，可能几十帧，上百帧的数据都是关联特别密切的。

对于这些关联特别密切的帧，其实我们只需要保存一帧的数据，其它帧都可以通过这一帧再按某种规则预测出来，所以说视频数据在时间上的冗余是最多的。

为了达到相关帧通过预测的方法来压缩数据，就需要将视频帧进行分组。那么如何判定某些帧关系密切，可以划为一组呢？

我们来看一下例子，下面是捕获的一组运动的台球的视频帧，台球从右上角滚到了左下角。

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107191042485-298715843.png)

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107191049911-566848692.png)

H264编码器会按顺序，每次取出两幅相邻的帧进行宏块比较，计算两帧的相似度。如下图：

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107191057909-1290432429.png)

通过宏块扫描与宏块搜索可以发现这两个帧的关联度是非常高的。进而发现这一组帧的关联度都是非常高的。因此，上面这几帧就可以划分为一组。其算法是：**在相邻几幅图像画面中，一般有差别的像素只有10%以内的点,亮度差值变化不超过2%，而色度差值的变化只有1%以内，我们认为这样的图可以分到一组。**

在这样一组帧中，经过编码后，我们只保留第一帖的完整数据，其它帧都通过参考上一帧计算出来。我们称第一帧为**IDR／I帧**，其它帧我们称为**P／B帧**，这样编码后的数据帧组我们称为**GOP**。

所以如果场景一直没什么变化，则一系列视频帧中 I 帧的数量会很少。如果场景变换很复杂，一直在场景变换大的场景切换时就会有 I 帧出现。

### 运动估计与运动补偿（帧间预测）

在 H264 编码器中将帧分组后，就要计算帧组内物体的**运动矢量**了。还以上面运动的台球视频帧为例，我们来看一下它是如何计算运动矢量的。

H264 编码器首先按顺序从缓冲区头部取出两帧视频数据，然后进行宏块扫描。当发现其中一幅图片中有物体时，就在另一幅图的邻近位置（搜索窗口中）进行搜索。如果此时在另一幅图中找到该物体，那么就可以计算出物体的运动矢量了。

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107191202143-1946967618.png)

通过上图中台球位置相差，就可以计算出台图运行的方向和距离。H264依次把每一帧中球移动的距离和方向都记录下来就成了下面的样子。

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107191209567-231318593.png)

运动矢量计算出来后，将相同部分（也就是绿色部分）减去，就得到了补偿数据。我们最终只需要将补偿数据进行压缩保存，以后在解码时就可以恢复原图了。压缩补偿后的数据只需要记录很少的一点数据。如下所示：

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107191214612-1864697524.png)

我们把运动矢量与补偿称为**帧间压缩技术**，它解决的是视频帧在时间上的数据冗余。除了帧间压缩，帧内也要进行数据压缩，帧内数据压缩解决的是空间上的数据冗余。下面我们就来介绍一下帧内压缩技术。

除了帧间压缩，帧内也要进行数据压缩，帧内数据压缩解决的是空间上的数据冗余。下面我们就来介绍一下帧内压缩技术。

### 帧内预测

人眼对图象都有一个识别度，对低频的亮度很敏感，对高频的亮度不太敏感。所以基于一些研究，可以将一幅图像中人眼不敏感的数据去除掉。这样就提出了帧内预测技术。

H264 的帧内压缩与 JPEG 很相似。一幅图像被划分好宏块后，对每个宏块可以进行 9 种模式的预测。找出与原图最接近的一种预测模式。

帧内预测后的图像与原始图像的对比如下：

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107191249101-214889465.png)

然后，将原始图像与帧内预测后的图像相减得残差值。

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107191253955-1987839456.png)

再将我们之前得到的预测模式信息一起保存起来，这样我们就可以在解码时恢复原图了。效果如下：

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107191259057-1084466018.png)

### 对残差数据做DCT转换

可以**将残差数据做整数离散余弦变换，去掉数据的相关性，进一步压缩数据**。

如下图所示，左侧为原数据的宏块，右侧为计算出的残差数据的宏块。

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107191314043-1719104258.png)

将残差数据宏块数字化后如下图所示：

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107191318906-1060673182.png)

将残差数据宏块进行 DCT 转换。

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107191325145-505363573.png)

去掉相关联的数据后，我们可以看出数据被进一步压缩了。

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107191330244-1287304627.png)

做完 DCT 后，还不够，还要进行 CABAC 进行无损压缩。

### CABAC 压缩

上面的帧内压缩是属于有损压缩技术。也就是说图像被压缩后，无法完全复原。而 CABAC 属于无损压缩技术。

无损压缩技术大家最熟悉的可能就是哈夫曼编码了，给高频的词一个短码，给低频词一个长码从而达到数据压缩的目的。

MPEG-2 中使用的 VLC 就是这种算法，我们以 A-Z 作为例子，**A 属于高频数据，Z 属于低频数据**。看看它是如何做的。

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107191345116-277907586.png)

CABAC也是给高频数据短码，给低频数据长码。同时还会根据上下文相关性进行压缩，这种方式又比VLC高效很多。其效果如下：

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107191350500-1400387362.png)

现在将 A-Z 换成视频帧，它就成了下面的样子。

![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1307424-20181107191355172-2085276841.png)

## 帧内预测详解

帧内预测（Intra Prediction）是H.264编码中用于减少同一帧内空间冗余的重要技术。它通过利用同一帧内的相邻像素来预测当前像素的值，从而生成预测块，并计算预测残差。以下是帧内预测的详细原理和过程，结合一个具体的实例进行解释。

### 帧内预测的原理
帧内预测的基本原理是利用已编码的相邻像素来预测当前块的像素值。H.264支持多种帧内预测模式，包括4x4亮度块的9种模式和16x16亮度块的4种模式。这些模式利用不同的方向和方式来生成预测块。

### 帧内预测的过程
1. **选择预测模式**：根据当前块的特性选择最合适的帧内预测模式。
2. **生成预测块**：利用相邻已编码的像素值来预测当前块的像素值，生成预测块。
3. **计算残差**：将原始块的像素值减去预测块的像素值，得到残差块。

### 实例解释
假设我们有一个4x4的亮度块，其原始像素值如下：

```
原始块：
100 102 104 106
101 103 105 107
102 104 106 108
103 105 107 109
```

假设相邻已编码的像素值如下：

```
相邻像素：
 98  99 100 101 102 103 104 105 106 107 108 109 110
```

#### 1. 选择预测模式
假设我们选择“垂直模式”（模式0），该模式利用上方相邻像素来预测当前块的像素值。

#### 2. 生成预测块
在垂直模式下，预测块的生成方式如下：
- 预测块的第一列像素值等于相邻像素的第一个值（100）。
- 预测块的第二列像素值等于相邻像素的第二个值（101）。
- 预测块的第三列像素值等于相邻像素的第三个值（102）。
- 预测块的第四列像素值等于相邻像素的第四个值（103）。

生成的预测块如下：

```
预测块（垂直模式）：
100 101 102 103
100 101 102 103
100 101 102 103
100 101 102 103
```

#### 3. 计算残差
将原始块的像素值减去预测块的像素值，得到残差块：

```
残差块：
  0   1   2   3
  1   2   3   4
  2   3   4   5
  3   4   5   6
```

### 其他预测模式
除了垂直模式，H.264还支持其他多种帧内预测模式，例如：

#### 水平模式（模式1）
- 利用左侧相邻像素来预测当前块的像素值。

#### DC模式（模式2）
- 利用上方和左侧相邻像素的平均值来预测当前块的像素值。

#### 对角线模式（模式3-8）
- 利用不同方向的相邻像素来预测当前块的像素值。

### 总结
帧内预测通过利用同一帧内的相邻像素来预测当前块的像素值，从而减少空间冗余。H.264支持多种帧内预测模式，每种模式利用不同的方向和方式来生成预测块。通过选择最合适的预测模式，并计算预测残差，H.264能够有效地压缩视频数据。

## I帧、P帧、B帧

在视频编码中，I帧、P帧和B帧是三种不同类型的帧，它们在视频压缩和传输中扮演着不同的角色。以下是它们的详细解释：

### I帧（Intra-coded frames，关键帧）
   - **定义**：I帧是独立编码的帧，不依赖于其他帧。它们是视频序列中的关键帧，可以单独解码和显示。
   - **特点**：
     - **独立性**：I帧不依赖于其他帧，因此可以独立解码和显示。
     - **高数据量**：由于I帧包含完整的图像信息，其数据量通常较大。
     - **低压缩率**：I帧的压缩率相对较低，因为它们需要保留完整的图像信息。
   - **用途**：
     - **视频序列的起点**：I帧通常作为视频序列的起点，后续的P帧和B帧依赖于I帧进行解码。
     - **随机访问**：I帧允许用户在视频中进行随机访问，例如快速跳转到某个时间点。
   - 确定I帧的一些常见方法和策略
     - 固定间隔：编码器按照固定的时间间隔插入I帧。例如，每隔1秒或每隔10帧插入一个I帧。
     - 场景切换检测：编码器通过检测视频中的场景切换来确定I帧的位置。场景切换通常意味着视频内容发生了显著变化，需要插入一个新的I帧。
     - 运动估计：编码器通过分析视频帧之间的运动情况来确定I帧的位置。如果相邻帧之间的运动量过大，编码器可能会插入一个新的I帧。
     - 编码器策略：编码器根据预设的策略和算法来确定I帧的位置。这些策略可能结合了固定间隔、场景切换检测和运动估计等多种方法。
     - 用户控制：用户可以通过编码器的设置或命令行参数来手动指定I帧的位置和频率。
     - 网络传输需求：在实时视频传输中，网络传输的需求也可能影响I帧的确定。例如，网络丢包或带宽变化可能导致编码器插入更多的I帧以确保视频的连续性和质量。


### P帧（Predicted frames，预测帧）
   - **定义**：P帧是依赖于先前的I帧或P帧进行预测编码的帧。它们通过运动估计和运动补偿来减少时间冗余。
   - **特点**：
     - **依赖性**：P帧依赖于先前的I帧或P帧，因此需要先解码这些帧才能解码P帧。
     - **中等数据量**：P帧的数据量通常介于I帧和B帧之间，因为它们只包含预测残差和运动矢量。
     - **中等压缩率**：P帧的压缩率较高，因为它们利用了时间冗余。
   - **用途**：
     - **时间冗余减少**：P帧通过运动估计和运动补偿来减少时间冗余，从而提高压缩效率。
     - **视频序列的连续性**：P帧用于保持视频序列的连续性，提供平滑的播放效果。

### B帧（Bi-directional frames，双向预测帧）
   - **定义**：B帧是依赖于先前和后续的I帧或P帧进行双向预测编码的帧。它们通过双向运动估计和运动补偿来减少时间冗余。
   - **特点**：
     - **双向依赖性**：B帧依赖于先前和后续的I帧或P帧，因此需要先解码这些帧才能解码B帧。
     - **低数据量**：B帧的数据量通常最小，因为它们只包含双向预测残差和运动矢量。
     - **高压缩率**：B帧的压缩率最高，因为它们利用了双向时间冗余。
   - **用途**：
     - **时间冗余减少**：B帧通过双向运动估计和运动补偿来进一步减少时间冗余，从而提高压缩效率。
     - **视频序列的平滑性**：B帧用于提高视频序列的平滑性和质量，特别是在快速运动场景中。

### 总结
- **I帧**：独立编码的帧，不依赖其他帧，数据量大，压缩率低，用于视频序列的起点和随机访问。
- **P帧**：依赖于先前的I帧或P帧进行预测编码，数据量中等，压缩率较高，用于减少时间冗余和保持视频序列的连续性。
- **B帧**：依赖于先前和后续的I帧或P帧进行双向预测编码，数据量最小，压缩率最高，用于进一步减少时间冗余和提高视频序列的平滑性。

通过合理使用I帧、P帧和B帧，视频编码器能够在保持较高图像质量的同时，显著减少视频数据的存储和传输需求。

参考：[【H264】压缩编码原理 - fengMisaka - 博客园](https://www.cnblogs.com/linuxAndMcu/p/14533195.html)