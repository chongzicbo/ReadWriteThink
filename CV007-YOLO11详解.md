2024 å¹´æ˜¯ YOLO æ¨¡å‹çš„ä¸€å¹´ã€‚åœ¨ 2023 å¹´å‘å¸ƒ Ultralytics YOLOv8 ä¹‹åï¼Œ YOLOv9 å’Œ YOLOv10ä¹Ÿåœ¨2024å¹´å‘å¸ƒäº†ã€‚ä½†ç­‰ç­‰ï¼Œè¿™è¿˜ä¸æ˜¯ç»“æŸï¼Ultralytics YOLO11 ç»ˆäºæ¥äº†ï¼Œåœ¨æ¿€åŠ¨äººå¿ƒçš„ YOLO Vision 2024 ï¼ˆYV24ï¼‰ æ´»åŠ¨ä¸­äº®ç›¸ã€‚

![](https://learnopencv.com/wp-content/uploads/2024/10/feature.gif)

YOLO11 ç³»åˆ—æ˜¯ YOLO ç³»åˆ—ä¸­æœ€å…ˆè¿›çš„ ï¼ˆSOTAï¼‰ã€æœ€è½»ã€æœ€é«˜æ•ˆçš„å‹å·ï¼Œæ€§èƒ½ä¼˜äºå…¶å‰ä»£äº§å“ã€‚å®ƒç”± Ultralytics åˆ›å»ºï¼Œè¯¥ç»„ç»‡å‘å¸ƒäº† YOLOv8ï¼Œè¿™æ˜¯è¿„ä»Šä¸ºæ­¢æœ€ç¨³å®šå’Œä½¿ç”¨æœ€å¹¿æ³›çš„ YOLO å˜ä½“ã€‚ç°åœ¨ï¼ŒYOLO11 å°†ç»§ç»­ YOLO ç³»åˆ—çš„ä¼ ç»Ÿã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨ï¼š

- **ä»€ä¹ˆæ˜¯ YOLO11ï¼Ÿ**
- **YOLO11 èƒ½åšä»€ä¹ˆï¼Ÿ**
- **YOLO11 æ¯”å…¶ä»– YOLO å˜ä½“æ›´é«˜æ•ˆå—ï¼Ÿ**
- **YOLO11 æ¶æ„æœ‰å“ªäº›æ”¹è¿›ï¼Ÿ**
- **YOLO11 çš„ä»£ç pipelineæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ**
- **YOLO11 çš„åŸºå‡†æµ‹è¯•**
- **YOLO11 å¿«é€Ÿå›é¡¾**

# ä»€ä¹ˆæ˜¯YOLO11

![](https://learnopencv.com/wp-content/uploads/2024/10/yolo11-1.png)

YOLO11 æ˜¯ Ultralytics çš„ YOLO ç³»åˆ—çš„æœ€æ–°ç‰ˆæœ¬ã€‚YOLO11 é…å¤‡äº†è¶…è½»é‡çº§å‹å·ï¼Œæ¯”ä»¥å‰çš„ YOLO æ›´å¿«ã€æ›´é«˜æ•ˆã€‚YOLO11 èƒ½å¤Ÿæ‰§è¡Œæ›´å¹¿æ³›çš„è®¡ç®—æœºè§†è§‰ä»»åŠ¡ã€‚Ultralytics æ ¹æ®å¤§å°å‘å¸ƒäº† 5 ä¸ª YOLO11 æ¨¡å‹ï¼Œå¹¶åœ¨**æ‰€æœ‰ä»»åŠ¡ä¸­å‘å¸ƒäº† 25 ä¸ªæ¨¡å‹**ï¼š

- **YOLO11n** â€“ Nano é€‚ç”¨äºå°å‹å’Œè½»é‡çº§ä»»åŠ¡ã€‚
- **YOLO11s** â€“ Nano çš„å°å‡çº§ï¼Œå…·æœ‰ä¸€äº›é¢å¤–çš„å‡†ç¡®æ€§ã€‚
- **YOLO11m** â€“ é€šç”¨å‹ã€‚
- **YOLO11l** â€“ å¤§ï¼Œç²¾åº¦æ›´é«˜ï¼Œè®¡ç®—é‡æ›´é«˜ã€‚
- **YOLO11x** â€“ è¶…å¤§å°ºå¯¸ï¼Œå¯å®ç°æœ€å¤§ç²¾åº¦å’Œæ€§èƒ½ã€‚

![](https://learnopencv.com/wp-content/uploads/2024/10/yolo11-model-table.png)

YOLO11 æ„å»ºåœ¨ Ultralytics YOLOv8 ä»£ç åº“ä¹‹ä¸Šï¼Œå¹¶è¿›è¡Œäº†ä¸€äº›æ¶æ„ä¿®æ”¹ã€‚å®ƒè¿˜é›†æˆäº†ä»¥å‰ YOLOï¼ˆå¦‚ YOLOv9 å’Œ YOLOv10ï¼‰çš„æ–°åŠŸèƒ½ï¼ˆæ”¹è¿›è¿™äº›åŠŸèƒ½ï¼‰ä»¥æé«˜æ€§èƒ½ã€‚æˆ‘ä»¬å°†åœ¨åšå®¢æ–‡ç« çš„åé¢éƒ¨åˆ†æ¢è®¨æ¶æ„å’Œä»£ç åº“ä¸­çš„æ–°å˜åŒ–ã€‚

# YOLO11çš„åº”ç”¨

YOLO ä»¥å…¶å¯¹è±¡æ£€æµ‹æ¨¡å‹è€Œé—»åã€‚ä½†æ˜¯ï¼ŒYOLO11 å¯ä»¥æ‰§è¡Œå¤šä¸ªè®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼Œä¾‹å¦‚ YOLOv8ã€‚å®ƒåŒ…æ‹¬ï¼š

- **å¯¹è±¡æ£€æµ‹**
- **å®ä¾‹åˆ†æ®µ**
- **å›¾åƒåˆ†ç±»**
- **å§¿åŠ¿ä¼°è®¡**
- **å®šå‘ç›®æ ‡æ£€æµ‹ ï¼ˆOBBï¼‰**

è®©æˆ‘ä»¬æ¥æ¢ç´¢æ‰€æœ‰è¿™äº›ã€‚

### å¯¹è±¡æ£€æµ‹

![yolo11-å¯¹è±¡æ£€æµ‹](https://cdn-ilcabpl.nitrocdn.com/XTpGTaZWYQSxctfMHQPVOQKOsBspWTQi/assets/images/optimized/rev-4cdf608/learnopencv.com/wp-content/uploads/2024/10/yolo11-object-detection.gif)

YOLO11 é€šè¿‡å°†è¾“å…¥å›¾åƒä¼ é€’åˆ° CNN ä»¥æå–ç‰¹å¾æ¥æ‰§è¡Œå¯¹è±¡æ£€æµ‹ã€‚ç„¶åï¼Œç½‘ç»œé¢„æµ‹è¿™äº›ç½‘æ ¼ä¸­å¯¹è±¡çš„è¾¹ç•Œæ¡†å’Œç±»æ¦‚ç‡ã€‚ä¸ºäº†å¤„ç†å¤šå°ºåº¦æ£€æµ‹ï¼Œä½¿ç”¨å›¾å±‚æ¥ç¡®ä¿æ£€æµ‹åˆ°å„ç§å¤§å°çš„ç‰©ä½“ã€‚ç„¶åä½¿ç”¨éæå¤§å€¼æŠ‘åˆ¶ ï¼ˆNMSï¼‰ æ¥ä¼˜åŒ–è¿™äº›é¢„æµ‹ï¼Œä»¥è¿‡æ»¤æ‰é‡å¤æˆ–ä½ç½®ä¿¡åº¦çš„æ¡†ï¼Œä»è€Œè·å¾—æ›´å‡†ç¡®çš„å¯¹è±¡æ£€æµ‹ã€‚YOLO11 åœ¨ MS-COCO æ•°æ®é›†ä¸Šè¿›è¡Œå¯¹è±¡æ£€æµ‹è®­ç»ƒï¼Œå…¶ä¸­åŒ…æ‹¬ 80 ä¸ªé¢„è®­ç»ƒç±»ã€‚

### å®ä¾‹åˆ†å‰²

![yolo åˆ†æ®µ](https://cdn-ilcabpl.nitrocdn.com/XTpGTaZWYQSxctfMHQPVOQKOsBspWTQi/assets/images/optimized/rev-4cdf608/learnopencv.com/wp-content/uploads/2024/10/yolo11-instance-segmentation-1.gif)

é™¤äº†æ£€æµ‹å¯¹è±¡ä¹‹å¤–ï¼ŒYOLO11 è¿˜é€šè¿‡æ·»åŠ æ©ç é¢„æµ‹åˆ†æ”¯æ‰©å±•åˆ°å®ä¾‹åˆ†å‰²ã€‚è¿™äº›æ¨¡å‹åœ¨ MS-COCO æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå…¶ä¸­åŒ…æ‹¬ 80 ä¸ªé¢„è®­ç»ƒç±»ã€‚æ­¤åˆ†æ”¯ä¸ºæ¯ä¸ªæ£€æµ‹åˆ°çš„å¯¹è±¡ç”Ÿæˆåƒç´ çº§åˆ†å‰²æ©ç ï¼Œä½¿æ¨¡å‹èƒ½å¤ŸåŒºåˆ†é‡å çš„å¯¹è±¡å¹¶æä¾›å…¶å½¢çŠ¶çš„ç²¾ç¡®è½®å»“ã€‚head ä¸­çš„è’™ç‰ˆåˆ†æ”¯å¤„ç†ç‰¹å¾æ˜ å°„å¹¶è¾“å‡ºå¯¹è±¡è’™ç‰ˆï¼Œä»è€Œåœ¨è¯†åˆ«å’ŒåŒºåˆ†å›¾åƒä¸­çš„å¯¹è±¡æ—¶å®ç°åƒç´ çº§ç²¾åº¦ã€‚

### å§¿åŠ¿ä¼°è®¡

![YOLO11 å§¿åŠ¿](./images/CV007-YOLO11%E8%AF%A6%E8%A7%A3/yolo11-pose-estimation.gif)

YOLO11 é€šè¿‡æ£€æµ‹å’Œé¢„æµ‹ç‰©ä½“ä¸Šçš„å…³é”®ç‚¹ï¼ˆä¾‹å¦‚äººä½“çš„å…³èŠ‚ï¼‰æ¥æ‰§è¡Œå§¿æ€ä¼°è®¡ã€‚å…³é”®ç‚¹è¿æ¥èµ·æ¥å½¢æˆéª¨æ¶ç»“æ„ï¼Œè¯¥ç»“æ„è¡¨ç¤ºå§¿åŠ¿ã€‚è¿™äº›æ¨¡å‹åœ¨ COCO ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå…¶ä¸­åŒ…æ‹¬ä¸€ä¸ªé¢„å…ˆè®­ç»ƒçš„ç±»â€œpersonâ€ã€‚

åœ¨å¤´éƒ¨æ·»åŠ å§¿æ€ä¼°è®¡å±‚ï¼Œå¹¶è®­ç»ƒç½‘ç»œé¢„æµ‹å…³é”®ç‚¹çš„åæ ‡ã€‚åå¤„ç†æ­¥éª¤å°†ç‚¹è¿æ¥èµ·æ¥ä»¥å½¢æˆéª¨æ¶ç»“æ„ï¼Œä»è€Œå®ç°å®æ—¶å§¿åŠ¿è¯†åˆ«ã€‚

### å›¾åƒåˆ†ç±»

![YOLO11 å›¾åƒåˆ†ç±»](./images/CV007-YOLO11%E8%AF%A6%E8%A7%A3/yolo11-image-classification.gif)

å¯¹äºå›¾åƒåˆ†ç±»ï¼ŒYOLO11 ä½¿ç”¨å…¶æ·±åº¦ç¥ç»ç½‘ç»œä»è¾“å…¥å›¾åƒä¸­æå–é«˜çº§ç‰¹å¾ï¼Œå¹¶å°†å…¶åˆ†é…ç»™å¤šä¸ªé¢„å®šä¹‰ç±»åˆ«ä¹‹ä¸€ã€‚è¿™äº›æ¨¡å‹åœ¨ ImageNet ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå…¶ä¸­åŒ…æ‹¬ 1000 ä¸ªé¢„è®­ç»ƒç±»ã€‚è¯¥ç½‘ç»œé€šè¿‡å¤šå±‚å·ç§¯å’Œæ± åŒ–å¤„ç†å›¾åƒï¼Œåœ¨å¢å¼ºåŸºæœ¬ç‰¹å¾çš„åŒæ—¶å‡å°‘ç©ºé—´ç»´åº¦ã€‚ç½‘ç»œé¡¶éƒ¨çš„åˆ†ç±»å¤´è¾“å‡ºé¢„æµ‹çš„ç±»ï¼Œä½¿å…¶é€‚ç”¨äºéœ€è¦è¯†åˆ«å›¾åƒæ•´ä½“ç±»åˆ«çš„ä»»åŠ¡ã€‚

### å®šå‘ç›®æ ‡æ£€æµ‹ ï¼ˆOBBï¼‰

![YOLO11-OBB](./images/CV007-YOLO11%E8%AF%A6%E8%A7%A3/yolo11-obb-detection-1.gif)

YOLO11 é€šè¿‡æ•´åˆ OBB æ‰©å±•äº†å¸¸è§„å¯¹è±¡æ£€æµ‹ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ£€æµ‹å’Œåˆ†ç±»æ—‹è½¬æˆ–ä¸è§„åˆ™æ–¹å‘çš„ç‰©ä½“ã€‚è¿™å¯¹äºèˆªç©ºå½±åƒåˆ†æç­‰åº”ç”¨ç¨‹åºç‰¹åˆ«æœ‰ç”¨ã€‚è¿™äº›æ¨¡å‹åœ¨ DOTAv1 ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå…¶ä¸­åŒ…æ‹¬ 15 ä¸ªé¢„è®­ç»ƒç±»ã€‚

![YOLO11-OBB](./images/CV007-YOLO11%E8%AF%A6%E8%A7%A3/yolo11-obb-logic-1-1024x615.png)

OBB æ¨¡å‹ä¸ä»…è¾“å‡ºè¾¹ç•Œæ¡†åæ ‡ï¼Œè¿˜è¾“å‡ºæ—‹è½¬è§’åº¦ ï¼ˆÎ¸ï¼‰ æˆ–å››ä¸ªè§’ç‚¹ã€‚è¿™äº›åæ ‡ç”¨äºåˆ›å»ºä¸å¯¹è±¡æ–¹å‘å¯¹é½çš„è¾¹ç•Œæ¡†ï¼Œä»è€Œæé«˜æ—‹è½¬å¯¹è±¡çš„æ£€æµ‹å‡†ç¡®æ€§ã€‚

# YOLO11 æ¶æ„å’Œ YOLO11 ä¸­çš„æ–°å¢åŠŸèƒ½

YOLO11 æ¶æ„æ˜¯å¯¹ YOLOv8 æ¶æ„çš„å‡çº§ï¼Œå…·æœ‰ä¸€äº›æ–°çš„é›†æˆå’Œå‚æ•°è°ƒæ•´ã€‚åœ¨æˆ‘ä»¬ç»§ç»­ä¸»è¦éƒ¨åˆ†ä¹‹å‰ï¼Œæ‚¨å¯ä»¥æŸ¥çœ‹æˆ‘ä»¬å…³äº [**YOLOv8**](https://learnopencv.com/ultralytics-yolov8/) çš„è¯¦ç»†æ–‡ç« ä»¥å¤§è‡´äº†è§£æ¶æ„ã€‚ç°åœ¨ï¼Œå¦‚æœä½ çœ‹ä¸€ä¸‹ YOLO11 çš„é…ç½®æ–‡ä»¶ï¼š

```yaml
# Parameters
nc: 80 # number of classes
scales: # model compound scaling constants, i.e. 'model=yolo11n.yaml' will call yolo11.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.50, 0.25, 1024] # summary: 319 layers, 2624080 parameters, 2624064 gradients, 6.6 GFLOPs
  s: [0.50, 0.50, 1024] # summary: 319 layers, 9458752 parameters, 9458736 gradients, 21.7 GFLOPs
  m: [0.50, 1.00, 512] # summary: 409 layers, 20114688 parameters, 20114672 gradients, 68.5 GFLOPs
  l: [1.00, 1.00, 512] # summary: 631 layers, 25372160 parameters, 25372144 gradients, 87.6 GFLOPs
  x: [1.00, 1.50, 512] # summary: 631 layers, 56966176 parameters, 56966160 gradients, 196.0 GFLOPs
 
# YOLO11n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2
  - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4
  - [-1, 2, C3k2, [256, False, 0.25]]
  - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8
  - [-1, 2, C3k2, [512, False, 0.25]]
  - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16
  - [-1, 2, C3k2, [512, True]]
  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32
  - [-1, 2, C3k2, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]] # 9
  - [-1, 2, C2PSA, [1024]] # 10
 
# YOLO11n head
head:
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 6], 1, Concat, [1]] # cat backbone P4
  - [-1, 2, C3k2, [512, False]] # 13
 
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 4], 1, Concat, [1]] # cat backbone P3
  - [-1, 2, C3k2, [256, False]] # 16 (P3/8-small)
 
  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 13], 1, Concat, [1]] # cat head P4
  - [-1, 2, C3k2, [512, False]] # 19 (P4/16-medium)
 
  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 10], 1, Concat, [1]] # cat head P5
  - [-1, 2, C3k2, [1024, True]] # 22 (P5/32-large)
 
  - [[16, 19, 22], 1, Detect, [nc]] # Detect(P3, P4, P5)
```

æ¶æ„çº§åˆ«çš„å˜åŒ–ï¼š

### **1. éª¨å¹²**

ä¸»å¹²æ˜¯æ¨¡å‹çš„ä¸€éƒ¨åˆ†ï¼Œç”¨äºä»å¤šä¸ªæ¯”ä¾‹çš„è¾“å…¥å›¾åƒä¸­æå–ç‰¹å¾ã€‚å®ƒé€šå¸¸æ¶‰åŠå †å å·ç§¯å±‚å’Œå—ä»¥åˆ›å»ºä¸åŒåˆ†è¾¨ç‡çš„ç‰¹å¾å›¾ã€‚

**å·ç§¯å±‚ï¼š**YOLO11 å…·æœ‰ç±»ä¼¼çš„ç»“æ„ï¼Œå¸¦æœ‰åˆå§‹å·ç§¯å±‚æ¥å¯¹å›¾åƒè¿›è¡Œä¸‹é‡‡æ ·ï¼š

```
- [-1, 1, Conv, [64, 3, 2]] # 0-P1/2
- [-1, 1, Conv, [128, 3, 2]] # 1-P2/4
```

- **C3k2 åŒºå—ï¼š**YOLO11 å¼•å…¥äº† **C3k2 å—ï¼Œè€Œä¸æ˜¯ C2f**ï¼Œå®ƒåœ¨è®¡ç®—æ–¹é¢æ•ˆç‡æ›´é«˜ã€‚æ­¤å—æ˜¯ **CSP ç“¶é¢ˆ**çš„è‡ªå®šä¹‰å®ç°ï¼Œå®ƒä½¿ç”¨ä¸¤ä¸ªå·ç§¯ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå¤§å‹å·ç§¯ï¼ˆå¦‚ YOLOv8 ä¸­æ‰€ç¤ºï¼‰ã€‚

  - **CSP ï¼ˆCross Stage Partialï¼‰ï¼š**CSP ç½‘ç»œæ‹†åˆ†ç‰¹å¾å›¾å¹¶é€šè¿‡ç“¶é¢ˆå±‚å¤„ç†ä¸€éƒ¨åˆ†ï¼ŒåŒæ—¶å°†å¦ä¸€éƒ¨åˆ†ä¸ç“¶é¢ˆçš„è¾“å‡ºåˆå¹¶ã€‚è¿™å‡å°‘äº†è®¡ç®—è´Ÿè½½å¹¶æ”¹å–„äº†ç‰¹å¾è¡¨ç¤ºã€‚

  ```
  - [-1, 2, C3k2, [256, False, 0.25]]
  ```

  - C3k2 å—è¿˜ä½¿ç”¨è¾ƒå°çš„å†…æ ¸å¤§å°ï¼ˆç”± k2 è¡¨ç¤ºï¼‰ï¼Œä½¿å…¶æ›´å¿«ï¼ŒåŒæ—¶ä¿æŒæ€§èƒ½ã€‚

  **SPPF å’Œ C2PSAï¼š**YOLO11 ä¿ç•™äº† SPPF å—ï¼Œä½†åœ¨ SPPF ä¹‹åæ·»åŠ äº†ä¸€ä¸ªæ–°çš„ **C2PSA** å—ï¼š

```
- [-1, 1, SPPF, [1024, 5]]
- [-1, 2, C2PSA, [1024]
```

- **C2PSA ï¼ˆCross Stage Partial with Spatial Attentionï¼‰** æ¨¡å—å¢å¼ºäº†ç‰¹å¾å›¾ä¸­çš„ç©ºé—´æ³¨æ„åŠ›ï¼Œä»è€Œæé«˜äº†æ¨¡å‹å¯¹å›¾åƒé‡è¦éƒ¨åˆ†çš„å…³æ³¨ã€‚è¿™ä½¿æ¨¡å‹èƒ½å¤Ÿé€šè¿‡åœ¨ç©ºé—´ä¸Šæ± åŒ–ç‰¹å¾æ¥æ›´æœ‰æ•ˆåœ°å…³æ³¨ç‰¹å®šçš„æ„Ÿå…´è¶£åŒºåŸŸã€‚

### **2. neck**

neck è´Ÿè´£èšåˆæ¥è‡ªä¸åŒåˆ†è¾¨ç‡çš„ç‰¹å¾ï¼Œå¹¶å°†å®ƒä»¬ä¼ é€’ç»™å¤´éƒ¨è¿›è¡Œé¢„æµ‹ã€‚å®ƒé€šå¸¸æ¶‰åŠæ¥è‡ªä¸åŒçº§åˆ«çš„ç‰¹å¾å›¾çš„ä¸Šé‡‡æ ·å’Œè¿æ¥ã€‚

**C3k2 åŒºå—ï¼š**YOLO11 ç”¨ **C3k2** å—æ›¿æ¢äº†é¢ˆéƒ¨çš„ C2f å—ã€‚å¦‚å‰æ‰€è¿°ï¼ŒC3k2 æ˜¯ä¸€ä¸ªæ›´å¿«ã€æ›´é«˜æ•ˆçš„åŒºå—ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸Šé‡‡æ ·å’Œä¸²è”åï¼ŒYOLO11 ä¸­çš„ neck å¦‚ä¸‹æ‰€ç¤ºï¼š

```
	
- [-1, 2, C3k2, [512, False]] # P4/16-medium
```

- æ­¤æ›´æ”¹æé«˜äº†è¦ç´ èšåˆè¿‡ç¨‹çš„é€Ÿåº¦å’Œæ€§èƒ½ã€‚
- **æ³¨æ„åŠ›æœºåˆ¶ï¼š**YOLO11 é€šè¿‡ **C2PSA** æ›´ä¾§é‡äºç©ºé—´æ³¨æ„åŠ›ï¼Œè¿™æœ‰åŠ©äºæ¨¡å‹ä¸“æ³¨äºå›¾åƒä¸­çš„å…³é”®åŒºåŸŸï¼Œä»¥ä¾¿æ›´å¥½åœ°æ£€æµ‹ã€‚è¿™åœ¨ YOLOv8 ä¸­æ˜¯ç¼ºå¤±çš„ï¼Œè¿™ä½¿å¾— YOLO11 åœ¨æ£€æµ‹è¾ƒå°æˆ–è¢«é®æŒ¡çš„å¯¹è±¡æ—¶å¯èƒ½æ›´å‡†ç¡®ã€‚

------

### **3. head**

head æ˜¯æ¨¡å‹ä¸­è´Ÿè´£ç”Ÿæˆæœ€ç»ˆé¢„æµ‹çš„éƒ¨åˆ†ã€‚åœ¨å¯¹è±¡æ£€æµ‹ä¸­ï¼Œè¿™é€šå¸¸æ„å‘³ç€ç”Ÿæˆè¾¹ç•Œæ¡†å¹¶å¯¹è¿™äº›æ¡†å†…çš„å¯¹è±¡è¿›è¡Œåˆ†ç±»ã€‚

**C3k2 åŒºå—ï¼š**ä¸é¢ˆéƒ¨ç±»ä¼¼ï¼ŒYOLO11 å–ä»£äº†å¤´éƒ¨çš„ **C2f** å—ã€‚

```
	
- [-1, 2, C3k2, [512, False]] # P4/16-medium

```

**æ£€æµ‹å±‚ï¼š**æœ€ç»ˆçš„ Detect å±‚ä¸ YOLOv8 ä¸­çš„å±‚ç›¸åŒï¼š

```
- [[16, 19, 22], 1, Detect, [nc]] # Detect(P3, P4, P5)

```

ä½¿ç”¨ C3k2 å—ä½¿æ¨¡å‹åœ¨æ¨ç†æ–¹é¢æ›´å¿«ï¼Œåœ¨å‚æ•°æ–¹é¢æ›´é«˜æ•ˆã€‚
é‚£ä¹ˆï¼Œè®©æˆ‘ä»¬çœ‹çœ‹æ–°å—ï¼ˆå±‚ï¼‰åœ¨ä»£ç ä¸­çš„æ ·å­ï¼š

------

é‚£ä¹ˆï¼Œè®©æˆ‘ä»¬çœ‹çœ‹æ–°å—ï¼ˆå±‚ï¼‰åœ¨ä»£ç ä¸­çš„æ ·å­ï¼š

1. **C3k2 åŒºå—ï¼ˆä»** **blocks.py** å¼€å§‹**ï¼‰ï¼š**
   - **C3k2** æ˜¯ **CSP ç“¶é¢ˆ**çš„æ›´å¿«ã€æ›´é«˜æ•ˆçš„å˜ä½“ã€‚å®ƒä½¿ç”¨ä¸¤ä¸ªå·ç§¯è€Œä¸æ˜¯ä¸€ä¸ªå¤§å‹å·ç§¯ï¼Œä»è€ŒåŠ å¿«äº†ç‰¹å¾æå–é€Ÿåº¦ã€‚

```
class C3k2(C2f):
    def __init__(self, c1, c2, n=1, c3k=False, e=0.5, g=1, shortcut=True):
        super().__init__(c1, c2, n, shortcut, g, e)
        self.m = nn.ModuleList(
            C3k(self.c, self.c, 2, shortcut, g) if c3k else Bottleneck(self.c, self.c, shortcut, g) for _ in range(n)
        )
```

2. **C3k å—ï¼ˆä»** **blocks.py** å¼€å§‹**ï¼‰**ï¼š

- **C3k** æ˜¯ä¸€ä¸ªæ›´çµæ´»çš„ç“¶é¢ˆæ¨¡å—ï¼Œå…è®¸è‡ªå®šä¹‰å†…æ ¸å¤§å°ã€‚è¿™å¯¹äºæå–å›¾åƒä¸­æ›´è¯¦ç»†çš„ç‰¹å¾éå¸¸æœ‰ç”¨ã€‚

```
class C3k(C3):
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5, k=3):
        super().__init__(c1, c2, n, shortcut, g, e)
        c_ = int(c2 * e)  # hidden channels
        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, k=(k, k), e=1.0) for _ in range(n)))
```

3. **C2PSA å—ï¼ˆä»** **blocks.py** å¹´èµ·**ï¼‰ï¼š**

- **C2PSA** ï¼ˆCross Stage Partial with Spatial Attentionï¼‰ å¢å¼ºäº†æ¨¡å‹çš„ç©ºé—´æ³¨æ„åŠ›èƒ½åŠ›ã€‚æ­¤æ¨¡å—å¢åŠ äº†å¯¹ç‰¹å¾å›¾çš„å…³æ³¨ï¼Œå¸®åŠ©æ¨¡å‹ä¸“æ³¨äºå›¾åƒçš„é‡è¦åŒºåŸŸã€‚

```
class C2PSA(nn.Module):
    def __init__(self, c1, c2, e=0.5):
        super().__init__()
        c_ = int(c2 * e)
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)
     
    def forward(self, x):
        return self.cv3(torch.cat((self.cv1(x), self.cv2(x)), 1))
```

# YOLO11 pipeline

åœ¨ [**ultralytics**](https://github.com/ultralytics/ultralytics) GitHub ä»“åº“ä¸­ï¼Œæˆ‘ä»¬å°†ä¸»è¦å…³æ³¨ï¼š

1. **nn/modules/** ä¸­çš„æ¨¡å—
   - **block.py**
   - **conv.py**
   - **head.py**
   - **transformer.py**
   - **utils.py**
2. **nn/tasks.py** æ–‡ä»¶

### 1. ä»£ç åº“æ¦‚è¿°

ä»£ç åº“è¢«æ„å»ºä¸ºå¤šä¸ªæ¨¡å—ï¼Œè¿™äº›æ¨¡å—å®šä¹‰äº† YOLO11 æ¨¡å‹ä¸­ä½¿ç”¨çš„å„ç§ç¥ç»ç½‘ç»œç»„ä»¶ã€‚è¿™äº›ç»„ä»¶åœ¨ nn/modules/ ç›®å½•ä¸­è¢«ç»„ç»‡åˆ°ä¸åŒçš„æ–‡ä»¶ä¸­ï¼š

- **block.py**ï¼šå®šä¹‰æ¨¡å‹ä¸­ä½¿ç”¨çš„å„ç§æ„å»ºå—ï¼ˆæ¨¡å—ï¼‰ï¼Œä¾‹å¦‚ç“¶é¢ˆã€CSP æ¨¡å—å’Œæ³¨æ„åŠ›æœºåˆ¶ã€‚
- **conv.py**ï¼šåŒ…å«å·ç§¯æ¨¡å—ï¼ŒåŒ…æ‹¬æ ‡å‡†å·ç§¯ã€æ·±åº¦å·ç§¯å’Œå…¶ä»–å˜ä½“ã€‚
- **head.py**ï¼šå®ç°è´Ÿè´£ç”Ÿæˆæœ€ç»ˆé¢„æµ‹ï¼ˆä¾‹å¦‚ï¼Œè¾¹ç•Œæ¡†ã€ç±»æ¦‚ç‡ï¼‰çš„æ¨¡å‹å¤´ã€‚
- **transformer.py**ï¼šåŒ…æ‹¬åŸºäº transformer çš„æ¨¡å—ï¼Œç”¨äºæ³¨æ„åŠ›æœºåˆ¶å’Œé«˜çº§ç‰¹å¾æå–ã€‚
- **utils.py**ï¼šæä¾›è·¨æ¨¡å—ä½¿ç”¨çš„å®ç”¨ç¨‹åºå‡½æ•°å’Œå¸®åŠ©ç¨‹åºç±»ã€‚

nn/tasks.py æ–‡ä»¶å®šä¹‰äº†ä¸åŒçš„ç‰¹å®šäºä»»åŠ¡çš„æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼Œæ£€æµ‹ã€åˆ†å‰²ã€åˆ†ç±»ï¼‰ï¼Œè¿™äº›æ¨¡å‹å°†è¿™äº›æ¨¡å—ç»„åˆæˆå®Œæ•´çš„æ¶æ„ã€‚

### 2. nn/modules/ ä¸­çš„æ¨¡å—

å¦‚å‰æ‰€è¿°ï¼ŒYOLO11 æ„å»ºåœ¨ YOLOv8 ä»£ç åº“ä¹‹ä¸Šã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†ä¸»è¦å…³æ³¨æ›´æ–°çš„è„šæœ¬ï¼š**block.py**ã€**conv.py** å’Œ **head.py** åœ¨è¿™é‡Œã€‚

#### **block.py**

æ­¤æ–‡ä»¶å®šä¹‰ YOLO11 æ¨¡å‹ä¸­ä½¿ç”¨çš„å„ç§æ„å»ºå—ã€‚è¿™äº›å—æ˜¯æ„æˆç¥ç»ç½‘ç»œå±‚çš„åŸºæœ¬ç»„ä»¶ã€‚

##### **å…³é”®ç»„ä»¶ï¼š**

1. ç“¶é¢ˆæ¨¡å—ï¼š
   - **Bottleneck**ï¼šå…·æœ‰å¯é€‰å¿«æ·æ–¹å¼è¿æ¥çš„æ ‡å‡†ç“¶é¢ˆæ¨¡å—ã€‚
   - **Res**ï¼šä½¿ç”¨ä¸€ç³»åˆ—å·ç§¯å’Œèº«ä»½å¿«æ·æ–¹å¼çš„æ®‹å·®å—ã€‚

```
class Bottleneck(nn.Module):
    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):
        super().__init__()
        c_ = int(c2 * e)
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_, c2, 3, 1, g=g)
        self.add = shortcut and c1 == c2
 
    def forward(self, x):
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))

```

- Bottleneck ç±»å®ç°äº†ä¸€ä¸ª bottleneck æ¨¡å—ï¼Œè¯¥æ¨¡å—å‡å°‘äº†é€šé“çš„æ•°é‡ï¼ˆé™ç»´ï¼‰ï¼Œç„¶åå†æ¬¡æ‰©å±•å®ƒä»¬ã€‚
- **ç»„ä»¶**ï¼š
  - self.cv1ï¼šä¸€ä¸ª 1Ã—1 å·ç§¯ï¼Œç”¨äºå‡å°‘é€šé“æ•°ã€‚
  - self.cv2ï¼šä¸€ä¸ª 3Ã—3 å·ç§¯ï¼Œç”¨äºå°†é€šé“æ•°å¢åŠ å›åŸå§‹é€šé“æ•°ã€‚
  - self.addï¼šä¸€ä¸ªå¸ƒå°”å€¼ï¼ŒæŒ‡ç¤ºæ˜¯å¦æ·»åŠ å¿«æ·æ–¹å¼è¿æ¥ã€‚
- **Forward Pass**ï¼šè¾“å…¥ x é€šè¿‡ cv1 å’Œ cv2 ä¼ é€’ã€‚å¦‚æœ self.add ä¸º Trueï¼Œåˆ™åŸå§‹è¾“å…¥ x å°†æ·»åŠ åˆ°è¾“å‡ºï¼ˆæ®‹å·®è¿æ¥ï¼‰ã€‚

2. CSP ï¼ˆCross Stage Partialï¼‰ æ¨¡å—ï¼š

- **BottleneckCSPï¼š**ç“¶é¢ˆæ¨¡å—çš„ CSP ç‰ˆæœ¬ã€‚
- **CSPBlock**ï¼šå…·æœ‰å¤šä¸ªç“¶é¢ˆå±‚çš„æ›´å¤æ‚çš„ CSP æ¨¡å—ã€‚

```
class BottleneckCSP(nn.Module):
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        super().__init__()
        c_ = int(c2 * e)
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = nn.Sequential(
            *[Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)]
        )
        self.cv3 = Conv(2 * c_, c2, 1)
        self.add = c1 == c2
 
    def forward(self, x):
        y1 = self.cv2(self.cv1(x))
        y2 = x if self.add else None
        return self.cv3(torch.cat((y1, y2), 1)) if y2 is not None else self.cv3(y1)

```

- CSPBottleneck æ¨¡å—å°†ç‰¹å¾å›¾åˆ†ä¸ºä¸¤éƒ¨åˆ†ã€‚ä¸€éƒ¨åˆ†é€šè¿‡ä¸€ç³»åˆ—ç“¶é¢ˆå±‚ï¼Œå¦ä¸€éƒ¨åˆ†ç›´æ¥è¿æ¥åˆ°è¾“å‡ºï¼Œä»è€Œé™ä½äº†è®¡ç®—æˆæœ¬å¹¶å¢å¼ºäº†æ¢¯åº¦æµã€‚
- **ç»„ä»¶**ï¼š
  - self.cv1ï¼šå‡å°‘é€šé“æ•°ã€‚
  - self.cv2ï¼šç“¶é¢ˆå±‚åºåˆ—ã€‚
  - self.cv3ï¼šåˆå¹¶åŠŸèƒ½å¹¶è°ƒæ•´é€šé“æ•°ã€‚
  - self.addï¼šç¡®å®šæ˜¯å¦æ·»åŠ å¿«æ·æ–¹å¼è¿æ¥ã€‚

3. å…¶ä»–æ¨¡å—ï¼š

- **SPPFï¼š**Spatial Pyramid Pooling Fast æ¨¡å—ï¼Œå¯åœ¨å¤šä¸ªæ¯”ä¾‹ä¸‹æ‰§è¡Œæ± åŒ–ã€‚
- **Concat**ï¼šæ²¿æŒ‡å®šç»´åº¦è¿æ¥å¤šä¸ª Tensorã€‚

```
class SPPF(nn.Module):
    def __init__(self, c1, c2, k=5):
        super().__init__()
        c_ = c1 // 2
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_ * 4, c2, 1, 1)
        self.m = nn.MaxPool2d(kernel_size=k, stride=1, padding=k // 2)
 
    def forward(self, x):
        x = self.cv1(x)
        y1 = self.m(x)
        y2 = self.m(y1)
        y3 = self.m(y2)
        return self.cv2(torch.cat([x, y1, y2, y3], 1))
```

- SPPF æ¨¡å—åœ¨ä¸åŒæ¯”ä¾‹ä¸‹æ‰§è¡Œæœ€å¤§æ± åŒ–ï¼Œå¹¶å°†ç»“æœè¿æ¥èµ·æ¥ä»¥æ•è·å¤šä¸ªç©ºé—´æ¯”ä¾‹çš„è¦ç´ ã€‚
- **ç»„ä»¶**ï¼š
  - self.cv1ï¼šå‡å°‘é€šé“æ•°ã€‚
  - self.cv2ï¼šè°ƒæ•´æ‹¼æ¥åçš„ Channel æ•°ã€‚
  - self.mï¼šæœ€å¤§æ± åŒ–å±‚æ•°ã€‚
- **Forward Pass**ï¼šè¾“å…¥ x é€šè¿‡ cv1ï¼Œç„¶åé€šè¿‡ä¸‰ä¸ªè¿ç»­çš„æœ€å¤§æ± åŒ–å±‚ï¼ˆy1ã€y2ã€y3ï¼‰ã€‚ç»“æœè¢«è¿æ¥å¹¶é€šè¿‡ cv2 ä¼ é€’ã€‚

##### **äº†è§£æ¦‚å¿µï¼š**

- **ç“¶é¢ˆå±‚**ï¼šç”¨äºé€šè¿‡åœ¨æ˜‚è´µçš„æ“ä½œä¹‹å‰å‡å°‘é€šé“æ•°å¹¶åœ¨ä¹‹åå¢åŠ é€šé“æ•°æ¥é™ä½è®¡ç®—å¤æ‚æ€§ã€‚
- **æ®‹å·®è¿æ¥**ï¼šé€šè¿‡ç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜æ¥å¸®åŠ©è®­ç»ƒæ›´æ·±çš„ç½‘ç»œã€‚
- **CSP æ¶æ„**ï¼šå°†ç‰¹å¾å›¾åˆ†ä¸ºä¸¤éƒ¨åˆ†;ä¸€éƒ¨åˆ†å‘ç”Ÿè½¬æ¢ï¼Œè€Œå¦ä¸€éƒ¨åˆ†ä¿æŒä¸å˜ï¼Œä»è€Œæé«˜å­¦ä¹ èƒ½åŠ›å¹¶å‡å°‘è®¡ç®—ã€‚

#### **conv.py**

æ­¤æ–‡ä»¶åŒ…å«å„ç§å·ç§¯æ¨¡å—ï¼ŒåŒ…æ‹¬æ ‡å‡†å·ç§¯å’Œä¸“ç”¨å·ç§¯ã€‚

##### **å…³é”®ç»„ä»¶ï¼š**

**æ ‡å‡†å·ç§¯æ¨¡å— ï¼ˆConvï¼‰ï¼š**

```
class Conv(nn.Module):
    default_act = nn.SiLU()  # default activation
 
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):
        super().__init__()
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()
 
    def forward(self, x):
        return self.act(self.bn(self.conv(x)))
```

- å®ç°å…·æœ‰æ‰¹é‡è§„èŒƒåŒ–å’Œæ¿€æ´»çš„æ ‡å‡†å·ç§¯å±‚ã€‚
- **ç»„ä»¶**ï¼š
  - self.convï¼šå·ç§¯å±‚ã€‚
  - self.bnï¼šæ‰¹é‡è§„èŒƒåŒ–ã€‚
  - self.actï¼šæ¿€æ´»å‡½æ•°ï¼ˆé»˜è®¤ä¸º nn.SiLUï¼ˆï¼‰ï¼‰çš„
- **Forward Pass**ï¼šåº”ç”¨å·ç§¯ï¼Œç„¶åè¿›è¡Œæ‰¹é‡è§„èŒƒåŒ–å’Œæ¿€æ´»ã€‚

**æ·±åº¦å·ç§¯ ï¼ˆDWConvï¼‰ï¼š**

```
class DWConv(Conv):
    def __init__(self, c1, c2, k=1, s=1, d=1, act=True):
        super().__init__(c1, c2, k, s, g=math.gcd(c1, c2), d=d, act=act)
```

- æ‰§è¡Œæ·±åº¦å·ç§¯ï¼Œå…¶ä¸­æ¯ä¸ªè¾“å…¥é€šé“å•ç‹¬å·ç§¯ã€‚
- **ç»„ä»¶**ï¼š
  - ç»§æ‰¿è‡ª Convã€‚
  - å°† groups å‚æ•°è®¾ç½®ä¸º c1 å’Œ c2 çš„æœ€å¤§å…¬çº¦æ•°ï¼Œä»è€Œæœ‰æ•ˆåœ°å¯¹æ¯ä¸ªé€šé“çš„å·ç§¯è¿›è¡Œåˆ†ç»„ã€‚

1. å…¶ä»–å·ç§¯æ¨¡å—ï¼š
   - **Conv2**ï¼šRepConv çš„ç®€åŒ–ç‰ˆæœ¬ï¼Œç”¨äºæ¨¡å‹å‹ç¼©å’ŒåŠ é€Ÿã€‚
   - **GhostConv**ï¼šå®ç° GhostNet çš„ ghost æ¨¡å—ï¼Œå‡å°‘ç‰¹æ€§å›¾ä¸­çš„å†—ä½™ã€‚
   - **RepConv**ï¼šå¯é‡æ–°å‚æ•°åŒ–çš„å·ç§¯å±‚ï¼Œå¯ä»¥ä»è®­ç»ƒæ¨¡å¼è½¬æ¢ä¸ºæ¨ç†æ¨¡å¼ã€‚

##### **äº†è§£æ¦‚å¿µï¼š**

- **è‡ªåŠ¨å¡«å…… ï¼ˆ****autopad****ï¼‰ï¼š**è‡ªåŠ¨è®¡ç®—ä¿æŒè¾“å‡ºå°ºå¯¸ä¸€è‡´æ‰€éœ€çš„å¡«å……ã€‚
- **æ·±åº¦å·ç§¯å’Œç‚¹å·ç§¯**ï¼šç”¨äº MobileNet æ¶æ„ï¼Œä»¥å‡å°‘è®¡ç®—ï¼ŒåŒæ—¶ä¿æŒå‡†ç¡®æ€§ã€‚
- **é‡æ–°å‚æ•°åŒ–**ï¼šRepConv ç­‰æŠ€æœ¯é€šè¿‡åˆå¹¶å±‚æ¥å®ç°é«˜æ•ˆçš„è®­ç»ƒå’Œæ›´å¿«çš„æ¨ç†ã€‚

#### **head.py**

æ­¤æ–‡ä»¶å®ç°äº†è´Ÿè´£ç”Ÿæˆæ¨¡å‹æœ€ç»ˆé¢„æµ‹çš„ head æ¨¡å—ã€‚

##### **å…³é”®ç»„ä»¶ï¼š**

**æ£€æµ‹å¤´ ï¼ˆDetectï¼‰ï¼š**

```
class Detect(nn.Module):
    def __init__(self, nc=80, ch=()):
        super().__init__()
        self.nc = nc  # number of classes
        self.nl = len(ch)  # number of detection layers
        self.reg_max = 16  # DFL channels
        self.no = nc + self.reg_max * 4  # number of outputs per anchor
        self.stride = torch.zeros(self.nl)  # strides computed during build
 
        # Define layers
        self.cv2 = nn.ModuleList(
            nn.Sequential(Conv(x, c2, 3), Conv(c2, c2, 3), nn.Conv2d(c2, 4 * self.reg_max, 1)) for x in ch
        )
        self.cv3 = nn.ModuleList(
            nn.Sequential(
                nn.Sequential(DWConv(x, x, 3), Conv(x, c3, 1)),
                nn.Sequential(DWConv(c3, c3, 3), Conv(c3, c3, 1)),
                nn.Conv2d(c3, self.nc, 1),
            )
            for x in ch
        )
        self.dfl = DFL(self.reg_max) if self.reg_max > 1 else nn.Identity()
```

- Detect ç±»å®šä¹‰è¾“å‡ºè¾¹ç•Œæ¡†åæ ‡å’Œç±»æ¦‚ç‡çš„æ£€æµ‹å¤´ã€‚
- **ç»„ä»¶**ï¼š
  - self.cv2ï¼šç”¨äºè¾¹ç•Œæ¡†å›å½’çš„å·ç§¯å±‚ã€‚
  - self.cv3ï¼šç”¨äºåˆ†ç±»çš„å·ç§¯å±‚ã€‚
  - self.dflï¼šç”¨äºè¾¹ç•Œæ¡†ç»†åŒ–çš„ Distribution Focal Loss æ¨¡å—ã€‚
- **Forward Pass**ï¼šå¤„ç†è¾“å…¥ç‰¹å¾æ˜ å°„å¹¶è¾“å‡ºè¾¹ç•Œæ¡†å’Œç±»çš„é¢„æµ‹ã€‚

**åˆ†å‰² ï¼ˆ****Segment****ï¼‰ï¼š**

```
class Segment(Detect):
    def __init__(self, nc=80, nm=32, npr=256, ch=()):
        super().__init__(nc, ch)
        self.nm = nm  # number of masks
        self.npr = npr  # number of prototypes
        self.proto = Proto(ch[0], self.npr, self.nm)  # protos
 
        c4 = max(ch[0] // 4, self.nm)
        self.cv4 = nn.ModuleList(nn.Sequential(Conv(x, c4, 3), Conv(c4, c4, 3), nn.Conv2d(c4, self.nm, 1)) for x in ch)

```

- æ‰©å±• Detect ç±»ä»¥åŒ…å«åˆ†æ®µåŠŸèƒ½ã€‚
- **ç»„ä»¶**ï¼š
  - self.protoï¼šç”Ÿæˆæ©ç åŸå‹ã€‚
  - self.cv4ï¼šæ©ç ç³»æ•°çš„å·ç§¯å±‚ã€‚
- **Forward Pass**ï¼šè¾“å‡ºè¾¹ç•Œæ¡†ã€ç±»æ¦‚ç‡å’Œæ©ç ç³»æ•°ã€‚

**å§¿åŠ¿ä¼°è®¡å¤´éƒ¨ ï¼ˆPoseï¼‰ï¼š**

```
class Pose(Detect):
    def __init__(self, nc=80, kpt_shape=(17, 3), ch=()):
        super().__init__(nc, ch)
        self.kpt_shape = kpt_shape  # number of keypoints, number of dimensions
        self.nk = kpt_shape[0] * kpt_shape[1]  # total number of keypoint outputs
 
        c4 = max(ch[0] // 4, self.nk)
        self.cv4 = nn.ModuleList(nn.Sequential(Conv(x, c4, 3), Conv(c4, c4, 3), nn.Conv2d(c4, self.nk, 1)) for x in ch)

```

- æ‰©å±•äº† Detect ç±»ï¼Œç”¨äºäººä½“å§¿åŠ¿ä¼°è®¡ä»»åŠ¡ã€‚
- **ç»„ä»¶**ï¼š
  - self.kpt_shapeï¼šå…³é”®ç‚¹çš„å½¢çŠ¶ï¼ˆå…³é”®ç‚¹çš„æ•°é‡ã€æ¯ä¸ªå…³é”®ç‚¹çš„ç»´åº¦ï¼‰ã€‚
  - self.cv4ï¼šç”¨äºå…³é”®ç‚¹å›å½’çš„å·ç§¯å±‚ã€‚
- **Forward Pass**ï¼šè¾“å‡ºè¾¹ç•Œæ¡†ã€ç±»æ¦‚ç‡å’Œå…³é”®ç‚¹åæ ‡ã€‚

##### **äº†è§£æ¦‚å¿µï¼š**

- **æ¨¡å—åŒ–**ï¼šé€šè¿‡æ‰©å±• Detect ç±»ï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºä¸åŒçš„ä»»åŠ¡åˆ›å»ºä¸“é—¨çš„ headï¼ŒåŒæ—¶é‡ç”¨é€šç”¨åŠŸèƒ½ã€‚
- **æ— é”šç‚¹æ£€æµ‹**ï¼šç°ä»£å¯¹è±¡æ£€æµ‹å™¨é€šå¸¸ä½¿ç”¨æ— é”šç‚¹æ–¹æ³•ï¼Œç›´æ¥é¢„æµ‹è¾¹ç•Œæ¡†ã€‚
- **å…³é”®ç‚¹ä¼°è®¡**ï¼šåœ¨å§¿åŠ¿ä¼°è®¡ä¸­ï¼Œæ¨¡å‹é¢„æµ‹è¡¨ç¤ºå…³èŠ‚æˆ–åœ°æ ‡çš„å…³é”®ç‚¹ã€‚

### 3. **nn/tasks.py** æ–‡ä»¶

```python
# Ultralytics YOLO <img draggable="false" role="img" class="emoji" alt="ğŸš€" src="https://s.w.org/images/core/emoji/15.0.3/svg/1f680.svg">, AGPL-3.0 license
 
import contextlib
import pickle
import types
from copy import deepcopy
from pathlib import Path
 
import torch
import torch.nn as nn
 
# Other imports...
 
class BaseModel(nn.Module):
    """The BaseModel class serves as a base class for all the models in the Ultralytics YOLO family."""
 
    def forward(self, x, *args, **kwargs):
        """Handles both training and inference, returns predictions or loss."""
        if isinstance(x, dict):
            return self.loss(x, *args, **kwargs)  # Training: return loss
        return self.predict(x, *args, **kwargs)  # Inference: return predictions
 
    def predict(self, x, profile=False, visualize=False, augment=False, embed=None):
        """Run a forward pass through the network for inference."""
        if augment:
            return self._predict_augment(x)
        return self._predict_once(x, profile, visualize, embed)
     
    def fuse(self, verbose=True):
        """Fuses Conv and BatchNorm layers for efficiency during inference."""
        for m in self.model.modules():
            if isinstance(m, (Conv, Conv2, DWConv)) and hasattr(m, "bn"):
                m.conv = fuse_conv_and_bn(m.conv, m.bn)
                delattr(m, "bn")
                m.forward = m.forward_fuse  # Use the fused forward
        return self
     
    # More BaseModel methods...
 
class DetectionModel(BaseModel):
    """YOLOv8 detection model."""
 
    def __init__(self, cfg="yolov8n.yaml", ch=3, nc=None, verbose=True):
        """Initialize the YOLOv8 detection model with config and parameters."""
        super().__init__()
        self.yaml = cfg if isinstance(cfg, dict) else yaml_model_load(cfg)
        self.model, self.save = parse_model(deepcopy(self.yaml), ch=ch, verbose=verbose)
        self.names = {i: f"{i}" for i in range(self.yaml["nc"])}  # Class names
        self.inplace = self.yaml.get("inplace", True)
 
        # Initialize strides
        m = self.model[-1]  # Detect() layer
        if isinstance(m, Detect):
            s = 256  # Max stride
            m.stride = torch.tensor([s / x.shape[-2] for x in self._predict_once(torch.zeros(1, ch, s, s))])
            self.stride = m.stride
            m.bias_init()  # Initialize biases
 
    # More DetectionModel methods...
 
class SegmentationModel(DetectionModel):
    """YOLOv8 segmentation model."""
 
    def __init__(self, cfg="yolov8n-seg.yaml", ch=3, nc=None, verbose=True):
        """Initialize YOLOv8 segmentation model with given config and parameters."""
        super().__init__(cfg=cfg, ch=ch, nc=nc, verbose=verbose)
 
    def init_criterion(self):
        """Initialize the loss criterion for the SegmentationModel."""
        return v8SegmentationLoss(self)
 
class PoseModel(DetectionModel):
    """YOLOv8 pose model."""
 
    def __init__(self, cfg="yolov8n-pose.yaml", ch=3, nc=None, data_kpt_shape=(None, None), verbose=True):
        """Initialize YOLOv8 Pose model."""
        if not isinstance(cfg, dict):
            cfg = yaml_model_load(cfg)
        if list(data_kpt_shape) != list(cfg["kpt_shape"]):
            cfg["kpt_shape"] = data_kpt_shape
        super().__init__(cfg=cfg, ch=ch, nc=nc, verbose=verbose)
 
    def init_criterion(self):
        """Initialize the loss criterion for the PoseModel."""
        return v8PoseLoss(self)
 
class ClassificationModel(BaseModel):
    """YOLOv8 classification model."""
 
    def __init__(self, cfg="yolov8n-cls.yaml", ch=3, nc=None, verbose=True):
        """Initialize the YOLOv8 classification model."""
        super().__init__()
        self._from_yaml(cfg, ch, nc, verbose)
 
    def _from_yaml(self, cfg, ch, nc, verbose):
        """Set YOLOv8 model configurations and define the model architecture."""
        self.yaml = cfg if isinstance(cfg, dict) else yaml_model_load(cfg)
        self.model, self.save = parse_model(deepcopy(self.yaml), ch=ch, verbose=verbose)
        self.names = {i: f"{i}" for i in range(self.yaml["nc"])}
        self.info()
 
    def reshape_outputs(model, nc):
        """Update a classification model to match the class count (nc)."""
        name, m = list((model.model if hasattr(model, "model") else model).named_children())[-1]
        if isinstance(m, nn.Linear):
            if m.out_features != nc:
                setattr(model, name, nn.Linear(m.in_features, nc))
 
    def init_criterion(self):
        """Initialize the loss criterion for the ClassificationModel."""
        return v8ClassificationLoss()
 
class Ensemble(nn.ModuleList):
    """Ensemble of models."""
 
    def __init__(self):
        """Initialize an ensemble of models."""
        super().__init__()
 
    def forward(self, x, augment=False, profile=False, visualize=False):
        """Generate the ensembleâ€™s final layer by combining outputs from each model."""
        y = [module(x, augment, profile, visualize)[0] for module in self]
        return torch.cat(y, 2), None  # Concatenate outputs along the third dimension
 
# Functions ------------------------------------------------------------------------------------------------------------
 
def parse_model(d, ch, verbose=True):
    """Parse a YOLO model.yaml dictionary into a PyTorch model."""
    import ast
 
    max_channels = float("inf")
    nc, act, scales = (d.get(x) for x in ("nc", "activation", "scales"))
    depth, width, kpt_shape = (d.get(x, 1.0) for x in ("depth_multiple", "width_multiple", "kpt_shape"))
 
    # Model scaling
    if scales:
        scale = d.get("scale")
        if not scale:networ
            scale = tuple(scales.keys())[0]
            LOGGER.warning(f"WARNING <img draggable="false" role="img" class="emoji" alt="âš ï¸" src="https://s.w.org/images/core/emoji/15.0.3/svg/26a0.svg"> no model scale passed. Assuming scale='{scale}'.")
        depth, width, max_channels = scales[scale]
 
    if act:
        Conv.default_act = eval(act)  # redefine default activation
        if verbose:
            LOGGER.info(f"Activation: {act}")
 
    # Logging and parsing layers
    if verbose:
        LOGGER.info(f"\n{'':>3}{'from':>20}{'n':>3}{'params':>10}  {'module':<45}{'arguments':<30}")
    ch = [ch]
    layers, save, c2 = [], [], ch[-1]
 
    for i, (f, n, m, args) in enumerate(d["backbone"] + d["head"]):  # from, number, module, args
        m = globals()[m] if m in globals() else getattr(nn, m[3:], m)  # get module
        for j, a in enumerate(args):
            if isinstance(a, str):
                with contextlib.suppress(ValueError):
                    args[j] = ast.literal_eval(a) if a in locals() else a
 
        n = max(round(n * depth), 1) if n > 1 else n  # depth gain
        if m in {Conv, Bottleneck, C2f, C3k2, ...}:  # Module list
            c1, c2 = ch[f], args[0]
            c2 = make_divisible(min(c2, max_channels) * width, 8)
            args = [c1, c2, *args[1:]]
            if m in {C2f, C3k2, ...}:  # Repeated layers
                args.insert(2, n)
                n = 1
        elif m in {Concat, Detect, ...}:  # Head layers
            args.append([ch[x] for x in f])
        # Append layers
        m_ = nn.Sequential(*(m(*args) for _ in range(n))) if n > 1 else m(*args)
        layers.append(m_)
 
        ch.append(c2)
        save.extend([x % i for x in ([f] if isinstance(f, int) else f) if x != -1])
 
        if verbose:
            LOGGER.info(f"{i:>3}{str(f):>20}{n:>3}{sum(x.numel() for x in m_.parameters()):10.0f}  {str(m):<45}{str(args):<30}")
 
    return nn.Sequential(*layers), sorted(save)
 
def yaml_model_load(path):
    """Load a YOLO model from a YAML file."""
    path = Path(path)
    unified_path = path.with_name(path.stem.replace("yolov8", "yolov"))
    yaml_file = check_yaml(str(unified_path), hard=False) or check_yaml(path)
    d = yaml_load(yaml_file)
    d["scale"] = guess_model_scale(path)
    d["yaml_file"] = str(path)
    return d
 
# More utility functions...
 
def guess_model_scale(model_path):
    """Extract the scale from the YAML file."""
    import re
    return re.search(r"yolov\d+([nslmx])", Path(model_path).stem).group(1)
 
def attempt_load_weights(weights, device=None, inplace=True, fuse=False):
    """Loads weights for a model or an ensemble of models."""
    ensemble = Ensemble()
    for w in weights if isinstance(weights, list) else [weights]:
        ckpt, _ = torch_safe_load(w)
        model = (ckpt.get("ema") or ckpt["model"]).to(device).float()
        model = model.fuse().eval() if fuse and hasattr(model, "fuse") else model.eval()
        ensemble.append(model)
 
    return ensemble if len(ensemble) > 1 else ensemble[-1]
 
```

æ­¤ tasks.py è„šæœ¬æ˜¯ä»£ç ç®¡é“çš„æ ¸å¿ƒéƒ¨åˆ†;å®ƒä»ç„¶ä½¿ç”¨ YOLOv8 æ–¹æ³•å’Œé€»è¾‘;æˆ‘ä»¬åªéœ€è¦å°† YOLO11 æ¨¡å‹è§£æåˆ°å…¶ä¸­ã€‚æ­¤è„šæœ¬ä¸“ä¸ºå„ç§è®¡ç®—æœºè§†è§‰ä»»åŠ¡è€Œè®¾è®¡ï¼Œä¾‹å¦‚å¯¹è±¡æ£€æµ‹ã€åˆ†å‰²ã€åˆ†ç±»ã€å§¿åŠ¿ä¼°è®¡ã€OBB ç­‰ã€‚å®ƒå®šä¹‰äº†ç”¨äºè®­ç»ƒã€æ¨ç†å’Œæ¨¡å‹ç®¡ç†çš„åŸºç¡€æ¨¡å‹ã€ç‰¹å®šäºä»»åŠ¡çš„æ¨¡å‹å’Œæ•ˆç”¨å‡½æ•°ã€‚

#### **å…³é”®ç»„ä»¶ï¼š**

- **Importsï¼š**è¯¥è„šæœ¬ä» Ultralytics å¯¼å…¥ PyTorch ï¼ˆtorchï¼‰ã€ç¥ç»ç½‘ç»œå±‚ ï¼ˆtorch.nnï¼‰ å’Œå®ç”¨å‡½æ•°ç­‰åŸºæœ¬æ¨¡å—ã€‚ä¸€äº›å…³é”®å¯¼å…¥åŒ…æ‹¬ï¼š
  - å¯¹ **C3k2**ã€**C2PSA**ã€**C3**ã€**SPPFã€****Concat** ç­‰æ¶æ„æ¨¡å—è¿›è¡Œå»ºæ¨¡ã€‚
  - æŸå¤±å‡½æ•°ï¼Œå¦‚ **v8DetectionLoss**ã€**v8SegmentationLoss**ã€**v8ClassificationLoss**ã€**v8OBBLoss**ã€‚
  - å„ç§å®ç”¨ç¨‹åºå‡½æ•°ï¼Œå¦‚ model_infoã€**fuse_conv_and_bn**ã€**scale_img** **time_sync**ï¼Œä»¥å¸®åŠ©è¿›è¡Œæ¨¡å‹å¤„ç†ã€åˆ†æå’Œè¯„ä¼°ã€‚

#### **æ¨¡å‹åŸºç±»ï¼š**

1. BaseModel ç±»ï¼š
   - BaseModel ç”¨ä½œ Ultralytics YOLO ç³»åˆ—ä¸­æ‰€æœ‰æ¨¡å‹çš„åŸºç±»ã€‚
   - å®ç°å¦‚ä¸‹åŸºæœ¬æ–¹æ³•ï¼š
     - **forwardï¼ˆï¼‰ï¼š**æ ¹æ®è¾“å…¥æ•°æ®å¤„ç†è®­ç»ƒå’Œæ¨ç†ã€‚
     - **predictï¼ˆï¼‰ï¼š**å¤„ç†å‰å‘ä¼ é€’ä»¥è¿›è¡Œæ¨ç†ã€‚
     - **fuseï¼ˆï¼‰ï¼š**èåˆ Conv2d å’Œ BatchNorm2d å±‚ä»¥æé«˜æ•ˆç‡ã€‚
     - **infoï¼ˆï¼‰ï¼š**æä¾›è¯¦ç»†çš„æ¨¡å‹ä¿¡æ¯ã€‚
   - æ­¤ç±»æ—¨åœ¨é€šè¿‡ç‰¹å®šäºä»»åŠ¡çš„æ¨¡å‹ï¼ˆä¾‹å¦‚æ£€æµ‹ã€åˆ†å‰²å’Œåˆ†ç±»ï¼‰è¿›è¡Œæ‰©å±•ã€‚
2. **DetectionModel** **ç±»ï¼š**
   - æ‰©å±• BaseModelï¼Œä¸“é—¨ç”¨äºå¯¹è±¡æ£€æµ‹ä»»åŠ¡ã€‚
   - åŠ è½½æ¨¡å‹é…ç½®ï¼Œåˆå§‹åŒ–æ£€æµ‹å¤´ï¼ˆå¦‚ Detect æ¨¡å—ï¼‰å¹¶è®¾ç½®æ¨¡å‹æ­¥å¹…ã€‚
   - å®ƒæ”¯æŒä½¿ç”¨ YOLOv8 ç­‰æ¶æ„çš„æ£€æµ‹ä»»åŠ¡ï¼Œå¹¶å¯ä»¥é€šè¿‡ **_predict_augmentï¼ˆï¼‰** æ‰§è¡Œå¢å¼ºæ¨ç†ã€‚

#### **ç‰¹å®šäºä»»åŠ¡çš„æ¨¡å‹ï¼š**

1. **SegmentationModel çš„ SegmentationModel** **ä¸­ï¼š**
   - ä¸“é—¨ç”¨äºåˆ†å‰²ä»»åŠ¡ï¼ˆå¦‚ YOLOv8 åˆ†å‰²ï¼‰çš„ DetectionModel çš„å­ç±»ã€‚
   - åˆå§‹åŒ–ç‰¹å®šäºåˆ†å‰²çš„æŸå¤±å‡½æ•° ï¼ˆv8SegmentationLossï¼‰ã€‚
2. **PoseModel çš„ PoseModel** **ä¸­ï¼š**
   - é€šè¿‡åˆå§‹åŒ–å…·æœ‰å…³é”®ç‚¹æ£€æµ‹ ï¼ˆ**kpt_shape**ï¼‰ ç‰¹å®šé…ç½®çš„æ¨¡å‹æ¥å¤„ç†å§¿æ€ä¼°è®¡ä»»åŠ¡ã€‚
   - ä½¿ç”¨ v8PoseLoss è¿›è¡Œç‰¹å®šäºå§¿åŠ¿çš„æŸå¤±è®¡ç®—ã€‚
3. **åˆ†ç±»å‹å·****ï¼š**
   - ä¸“ä¸ºä½¿ç”¨ YOLOv8 åˆ†ç±»æ¶æ„çš„å›¾åƒåˆ†ç±»ä»»åŠ¡è€Œè®¾è®¡ã€‚
   - åˆå§‹åŒ–å’Œç®¡ç†ç‰¹å®šäºåˆ†ç±»çš„æŸå¤± ï¼ˆ**v8ClassificationLoss**ï¼‰ã€‚
   - å®ƒè¿˜æ”¯æŒé‡å¡‘ç”¨äºåˆ†ç±»ä»»åŠ¡çš„é¢„è®­ç»ƒ TorchVision æ¨¡å‹ã€‚
4. **OBBå‹å·****ï¼š**
   - ç”¨äºå®šå‘è¾¹ç•Œæ¡† ï¼ˆOBBï¼‰ æ£€æµ‹ä»»åŠ¡ã€‚
   - å®ç°ç‰¹å®šçš„æŸå¤±å‡½æ•° ï¼ˆ**v8OBBLoss**ï¼‰ æ¥å¤„ç†æ—‹è½¬çš„è¾¹ç•Œæ¡†ã€‚
5. **ä¸–ç•Œæ¨¡å‹****ï¼š**
   - æ­¤æ¨¡å‹å¤„ç†å›¾åƒå­—å¹•å’ŒåŸºäºæ–‡æœ¬çš„è¯†åˆ«ç­‰ä»»åŠ¡ã€‚
   - åˆ©ç”¨ CLIP æ¨¡å‹ä¸­çš„æ–‡æœ¬ç‰¹å¾æ‰§è¡ŒåŸºäºæ–‡æœ¬çš„è§†è§‰è¯†åˆ«ä»»åŠ¡ã€‚
   - åŒ…æ‹¬å¯¹æ–‡æœ¬åµŒå…¥ ï¼ˆ**txt_feats**ï¼‰ çš„ç‰¹æ®Šå¤„ç†ï¼Œç”¨äºå­—å¹•å’Œä¸–ç•Œç›¸å…³ä»»åŠ¡ã€‚

#### **é›†æˆæ¨¡å‹ï¼š**

1. **é›†æˆ****ï¼š**
   - ä¸€ä¸ªç®€å•çš„ ensemble ç±»ï¼Œå®ƒå°†å¤šä¸ªæ¨¡å‹åˆå¹¶ä¸ºä¸€ä¸ªæ¨¡å‹ã€‚
   - å…è®¸å¯¹ä¸åŒæ¨¡å‹çš„è¾“å‡ºè¿›è¡Œå¹³å‡æˆ–ä¸²è”ï¼Œä»¥æé«˜æ•´ä½“æ€§èƒ½ã€‚
   - å¯¹äºç»„åˆå¤šä¸ªæ¨¡å‹çš„è¾“å‡ºæä¾›æ›´å¥½çš„é¢„æµ‹çš„ä»»åŠ¡éå¸¸æœ‰ç”¨ã€‚

#### **å®ç”¨åŠŸèƒ½ï¼š**

1. æ¨¡å‹åŠ è½½å’Œç®¡ç†ï¼š
   - **attempt_load_weightsï¼ˆï¼‰ã€****attempt_load_one_weightï¼ˆï¼‰**ï¼šç”¨äºåŠ è½½æ¨¡å‹ã€ç®¡ç†é›†æˆæ¨¡å‹ä»¥åŠå¤„ç†åŠ è½½é¢„è®­ç»ƒæƒé‡æ—¶çš„å…¼å®¹æ€§é—®é¢˜çš„å‡½æ•°ã€‚
   - è¿™äº›åŠŸèƒ½å¯ç¡®ä¿ä»¥é€‚å½“çš„æ­¥å¹…ã€å±‚å’Œé…ç½®æ­£ç¡®åŠ è½½æ¨¡å‹ã€‚
2. ä¸´æ—¶æ¨¡å—é‡å®šå‘ï¼š
   - **temporary_modulesï¼ˆï¼‰**ï¼šä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç”¨äºä¸´æ—¶é‡å®šå‘æ¨¡å—è·¯å¾„ï¼Œç¡®ä¿åœ¨æ¨¡å—ä½ç½®æ›´æ”¹æ—¶å‘åå…¼å®¹ã€‚
   - æœ‰åŠ©äºä¿æŒä¸æ—§å‹å·ç‰ˆæœ¬çš„å…¼å®¹æ€§ã€‚
3. **Pickle**å®‰å…¨å¤„ç†ï¼š
   - SafeUnpicklerï¼šä¸€ä¸ªè‡ªå®šä¹‰çš„è§£å°å™¨ï¼Œå¯ä»¥å®‰å…¨åœ°åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹ï¼Œç¡®ä¿æœªçŸ¥ç±»è¢«å®‰å…¨çš„å ä½ç¬¦ï¼ˆSafeClassï¼‰æ›¿æ¢ï¼Œä»¥é¿å…åœ¨åŠ è½½è¿‡ç¨‹ä¸­å‘ç”Ÿå´©æºƒã€‚

#### **æ¨¡å‹è§£æï¼š**

1. **parse_modelï¼ˆï¼‰** **ä¸­ï¼š**
   - æ­¤å‡½æ•°å°† YAML æ–‡ä»¶ä¸­çš„æ¨¡å‹é…ç½®è§£æä¸º PyTorch æ¨¡å‹ã€‚
   - å®ƒå¤„ç†ä¸»å¹²å’Œå¤´æ¶æ„ï¼Œè§£é‡Šæ¯ä¸ªå±‚ç±»å‹ï¼ˆå¦‚ Convã€SPPFã€Detectï¼‰ï¼Œå¹¶æ„å»ºæœ€ç»ˆæ¨¡å‹ã€‚
   - æ”¯æŒå„ç§æ¶æ„ï¼ŒåŒ…æ‹¬ C3k2ã€C2PSA ç­‰ YOLO11 ç»„ä»¶ã€‚
2. YAML æ¨¡å‹åŠ è½½ï¼š
   - **yaml_model_loadï¼ˆï¼‰**ï¼‰ï¼šä» YAML æ–‡ä»¶åŠ è½½æ¨¡å‹é…ç½®ï¼Œæ£€æµ‹æ¨¡å‹æ¯”ä¾‹ï¼ˆä¾‹å¦‚ nã€sã€mã€lã€xï¼‰å¹¶ç›¸åº”åœ°è°ƒæ•´å‚æ•°ã€‚
   - **guess_model_scaleï¼ˆï¼‰ã€****guess_model_taskï¼ˆï¼‰**ï¼šç”¨äºæ ¹æ® YAML æ–‡ä»¶ç»“æ„æ¨æ–­æ¨¡å‹è§„æ¨¡å’Œä»»åŠ¡çš„è¾…åŠ©å‡½æ•°ã€‚